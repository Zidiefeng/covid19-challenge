{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import nltk.corpus  \n",
    "from nltk.text import Text\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "#from nltk.corpus import gutenber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-576-7c278a2f3a8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install transformers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertForQuestionAnswering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForQuestionAnswering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-large-uncased-whole-word-masking-finetuned-squad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;31m# Ensure new system_piped implementation is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawnb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pexpect-U\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Vanilla Pexpect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mflush\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<pexpect factory incomplete>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreexec_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_poll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_poll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         self.ptyproc = self._spawnpty(self.args, env=self.env,\n\u001b[0;32m--> 304\u001b[0;31m                                      cwd=self.cwd, **kwargs)\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptyproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_spawnpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;34m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mptyprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPtyProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ptyprocess/ptyprocess.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_native_pty_fork\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;31m# Use internal fork_pty, for Solaris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/pty.py\u001b[0m in \u001b[0;36mfork\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mmaster_fd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslave_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHILD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Establish a new session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pdf_df = pd.read_csv(\"/home/jupyter/covid19-challenge/data/clean_doc_pdf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"/home/jupyter/covid19-challenge/data/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>sha</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>pdf_json_files</th>\n",
       "      <th>pmc_json_files</th>\n",
       "      <th>url</th>\n",
       "      <th>s2_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ug7v899j</td>\n",
       "      <td>d1aafb70c066a2068b02786f8929fd9c900897fb</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Clinical features of culture-proven Mycoplasma...</td>\n",
       "      <td>10.1186/1471-2334-1-6</td>\n",
       "      <td>PMC35282</td>\n",
       "      <td>11472636.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>OBJECTIVE: This retrospective chart review des...</td>\n",
       "      <td>2001-07-04</td>\n",
       "      <td>Madani, Tariq A; Al-Ghamdi, Aisha A</td>\n",
       "      <td>BMC Infect Dis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/d1aafb70c066a2068b027...</td>\n",
       "      <td>document_parses/pmc_json/PMC35282.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02tnwd4m</td>\n",
       "      <td>6b0567729c2143a66d737eb0a2f63f2dce2e5a7d</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Nitric oxide: a pro-inflammatory mediator in l...</td>\n",
       "      <td>10.1186/rr14</td>\n",
       "      <td>PMC59543</td>\n",
       "      <td>11667967.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Inflammatory diseases of the respiratory tract...</td>\n",
       "      <td>2000-08-15</td>\n",
       "      <td>Vliet, Albert van der; Eiserich, Jason P; Cros...</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/6b0567729c2143a66d737...</td>\n",
       "      <td>document_parses/pmc_json/PMC59543.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ejv2xln0</td>\n",
       "      <td>06ced00a5fc04215949aa72528f2eeaae1d58927</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Surfactant protein-D and pulmonary host defense</td>\n",
       "      <td>10.1186/rr19</td>\n",
       "      <td>PMC59549</td>\n",
       "      <td>11667972.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Surfactant protein-D (SP-D) participates in th...</td>\n",
       "      <td>2000-08-25</td>\n",
       "      <td>Crouch, Erika C</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/06ced00a5fc04215949aa...</td>\n",
       "      <td>document_parses/pmc_json/PMC59549.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2b73a28n</td>\n",
       "      <td>348055649b6b8cf2b9a376498df9bf41f7123605</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Role of endothelin-1 in lung disease</td>\n",
       "      <td>10.1186/rr44</td>\n",
       "      <td>PMC59574</td>\n",
       "      <td>11686871.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Endothelin-1 (ET-1) is a 21 amino acid peptide...</td>\n",
       "      <td>2001-02-22</td>\n",
       "      <td>Fagan, Karen A; McMurtry, Ivan F; Rodman, David M</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/348055649b6b8cf2b9a37...</td>\n",
       "      <td>document_parses/pmc_json/PMC59574.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9785vg6d</td>\n",
       "      <td>5f48792a5fa08bed9f56016f4981ae2ca6031b32</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Gene expression in epithelial cells in respons...</td>\n",
       "      <td>10.1186/rr61</td>\n",
       "      <td>PMC59580</td>\n",
       "      <td>11686888.0</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Respiratory syncytial virus (RSV) and pneumoni...</td>\n",
       "      <td>2001-05-11</td>\n",
       "      <td>Domachowske, Joseph B; Bonville, Cynthia A; Ro...</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document_parses/pdf_json/5f48792a5fa08bed9f560...</td>\n",
       "      <td>document_parses/pmc_json/PMC59580.xml.json</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cord_uid                                       sha source_x  \\\n",
       "0  ug7v899j  d1aafb70c066a2068b02786f8929fd9c900897fb      PMC   \n",
       "1  02tnwd4m  6b0567729c2143a66d737eb0a2f63f2dce2e5a7d      PMC   \n",
       "2  ejv2xln0  06ced00a5fc04215949aa72528f2eeaae1d58927      PMC   \n",
       "3  2b73a28n  348055649b6b8cf2b9a376498df9bf41f7123605      PMC   \n",
       "4  9785vg6d  5f48792a5fa08bed9f56016f4981ae2ca6031b32      PMC   \n",
       "\n",
       "                                               title                    doi  \\\n",
       "0  Clinical features of culture-proven Mycoplasma...  10.1186/1471-2334-1-6   \n",
       "1  Nitric oxide: a pro-inflammatory mediator in l...           10.1186/rr14   \n",
       "2    Surfactant protein-D and pulmonary host defense           10.1186/rr19   \n",
       "3               Role of endothelin-1 in lung disease           10.1186/rr44   \n",
       "4  Gene expression in epithelial cells in respons...           10.1186/rr61   \n",
       "\n",
       "      pmcid   pubmed_id license  \\\n",
       "0  PMC35282  11472636.0   no-cc   \n",
       "1  PMC59543  11667967.0   no-cc   \n",
       "2  PMC59549  11667972.0   no-cc   \n",
       "3  PMC59574  11686871.0   no-cc   \n",
       "4  PMC59580  11686888.0   no-cc   \n",
       "\n",
       "                                            abstract publish_time  \\\n",
       "0  OBJECTIVE: This retrospective chart review des...   2001-07-04   \n",
       "1  Inflammatory diseases of the respiratory tract...   2000-08-15   \n",
       "2  Surfactant protein-D (SP-D) participates in th...   2000-08-25   \n",
       "3  Endothelin-1 (ET-1) is a 21 amino acid peptide...   2001-02-22   \n",
       "4  Respiratory syncytial virus (RSV) and pneumoni...   2001-05-11   \n",
       "\n",
       "                                             authors         journal  mag_id  \\\n",
       "0                Madani, Tariq A; Al-Ghamdi, Aisha A  BMC Infect Dis     NaN   \n",
       "1  Vliet, Albert van der; Eiserich, Jason P; Cros...      Respir Res     NaN   \n",
       "2                                    Crouch, Erika C      Respir Res     NaN   \n",
       "3  Fagan, Karen A; McMurtry, Ivan F; Rodman, David M      Respir Res     NaN   \n",
       "4  Domachowske, Joseph B; Bonville, Cynthia A; Ro...      Respir Res     NaN   \n",
       "\n",
       "  who_covidence_id arxiv_id  \\\n",
       "0              NaN      NaN   \n",
       "1              NaN      NaN   \n",
       "2              NaN      NaN   \n",
       "3              NaN      NaN   \n",
       "4              NaN      NaN   \n",
       "\n",
       "                                      pdf_json_files  \\\n",
       "0  document_parses/pdf_json/d1aafb70c066a2068b027...   \n",
       "1  document_parses/pdf_json/6b0567729c2143a66d737...   \n",
       "2  document_parses/pdf_json/06ced00a5fc04215949aa...   \n",
       "3  document_parses/pdf_json/348055649b6b8cf2b9a37...   \n",
       "4  document_parses/pdf_json/5f48792a5fa08bed9f560...   \n",
       "\n",
       "                               pmc_json_files  \\\n",
       "0  document_parses/pmc_json/PMC35282.xml.json   \n",
       "1  document_parses/pmc_json/PMC59543.xml.json   \n",
       "2  document_parses/pmc_json/PMC59549.xml.json   \n",
       "3  document_parses/pmc_json/PMC59574.xml.json   \n",
       "4  document_parses/pmc_json/PMC59580.xml.json   \n",
       "\n",
       "                                                 url  s2_id  \n",
       "0  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3...    NaN  \n",
       "1  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  \n",
       "2  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  \n",
       "3  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  \n",
       "4  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...    NaN  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paper_id', 'title_x', 'authors_x', 'affiliations', 'abstract_x',\n",
       "       'text', 'bibliography', 'raw_authors', 'raw_bibliography', 'sha',\n",
       "       'title_y', 'authors_y', 'abstract_y', 'doi', 'publish_time', 'journal',\n",
       "       'text_cleaned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_pdf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.kaggle.com/colinlagator/cord-19-regex-and-webscraping-booz-allen\n",
    "keyword_list = ['novel coronavirus', 'novel-coronavirus', 'coronavirus-2019', 'sars-cov-2', 'sarscov2', 'covid-19', 'covid19',\n",
    "                        '2019ncov', '2019-ncov', 'wuhan']\n",
    "\n",
    "\n",
    "covid19_index_list = []\n",
    "for i, row in clean_pdf_df.iterrows():\n",
    "    text = row['text'].lower()\n",
    "    has_keyword = False\n",
    "    for keyword in keyword_list:\n",
    "        if keyword in text:\n",
    "            has_keyword = True\n",
    "            break\n",
    "    if has_keyword == True:\n",
    "        covid19_index_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pdf_df = clean_pdf_df.iloc[covid19_index_list, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(set(clean_pdf_df['paper_id']).intersection(metadata['sha']))  # ~7,000 papers not in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pdf_df = clean_pdf_df.merge(metadata[['sha', 'title', 'authors', 'abstract', 'doi', 'publish_time', 'journal']], how ='left', left_on='paper_id', right_on='sha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "def clean_sent(sentence):\n",
    "    \"\"\"\n",
    "    Clean the sentence\n",
    "    :param sentence: text to to be cleaned\n",
    "    :return: text that has been cleaned\n",
    "    \"\"\"\n",
    "    #nltk.FreqDist(words).most_common(10)\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    words = sentence.split()\n",
    "    # Lowercase all words (default_stopwords are lowercase too)\n",
    "    words = [word.lower() for word in words]\n",
    "    #words = sentence\n",
    "    words = [word for word in words if len(word) > 1]\n",
    "    # Remove numbers\n",
    "    words = [word for word in words if not word.isnumeric()]\n",
    "    # Remove punctuation\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    # Porter\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    #fdist = nltk.FreqDist(words_lc)   \n",
    "    return \" \".join(words)\n",
    "\n",
    "def clean_df(df,input_col_name,output_col_name):\n",
    "    \"\"\"\n",
    "    Clean the dataframe\n",
    "    :param df: dataframe to be cleaned\n",
    "    :param input_col_name: intput column name that contained the body text\n",
    "    :param output_col_name: output column name\n",
    "    :return: dataframe that has been cleaned with new column \"text_clean\"\n",
    "    \"\"\"\n",
    "    # split to sentences\n",
    "    #sample1['tokens_p_t'] = sample1['tokens_p'].apply(lambda x: x.split(\".\"))\n",
    "    df[output_col_name] = df.apply(lambda row: nltk.sent_tokenize(row[input_col_name]), axis=1)\n",
    "    print (df[output_col_name])\n",
    "    # clean sentences\n",
    "    df[output_col_name] = df.apply(lambda row: clean_sent(row[output_col_name]), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, answer_text):\n",
    "    '''\n",
    "    Takes a `question` string and an `answer_text` string (which contains the\n",
    "    answer), and identifies the words within the `answer_text` that are the\n",
    "    answer. Prints them out.\n",
    "    '''\n",
    "    # ======== Tokenize ========\n",
    "    # Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "    input_ids = tokenizer.encode(question, answer_text,max_length=500\n",
    "                                )\n",
    "\n",
    "    # Report how long the input sequence is.\n",
    "    #print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
    "\n",
    "    # ======== Set Segment IDs ========\n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    # The number of segment A tokens includes the [SEP] token istelf.\n",
    "    num_seg_a = sep_index + 1\n",
    "\n",
    "    # The remainder are segment B.\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # Construct the list of 0s and 1s.\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    # There should be a segment_id for every input token.\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "    # ======== Evaluate ========\n",
    "    # Run our example question through the model.\n",
    "    start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                                    token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\n",
    "\n",
    "    # ======== Reconstruct Answer ========\n",
    "    # Find the tokens with the highest `start` and `end` scores.\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "    \n",
    "    \n",
    "    # Get the string versions of the input tokens.\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # Start with the first token.\n",
    "    answer = tokens[answer_start]\n",
    "\n",
    "    # Select the remaining answer tokens and join them with whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        \n",
    "        # If it's a subword token, then recombine it with the previous token.\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        \n",
    "        # Otherwise, add a space then the token.\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "            \n",
    "    s_scores = start_scores.detach().numpy().flatten()\n",
    "    e_scores = end_scores.detach().numpy().flatten()\n",
    "    #print('score:'+(start_scores)+\"; \"+str(end_scores))\n",
    "    #print('score:'+str(max(s_scores))+\"; \"+str(min(e_scores)))\n",
    "    #print(str(tensor[torch.argmax(start_scores)]))\n",
    "    #print('Answer: \"' + answer + '\"')\n",
    "    #[answer,str(max(s_scores)),len(input_ids)]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_pdf_df = clean_pdf_df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "start = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pdf_df['text_cleaned'] = clean_pdf_df.apply(lambda row: clean_sent(row['text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2766.680513938016"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end = timer()\n",
    "clean_time = end-start\n",
    "clean_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = clean_pdf_df['text_cleaned']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper selection by similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"Can the virus be transmitted asymptomatically or during the incubation period\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_cleaned = [clean_sent(ques) for ques in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_simlarity_score(question_list, text_list, threshold=None, top=None):\n",
    "    dic = {}\n",
    "    tfidf = TfidfVectorizer()\n",
    "    corpus_tfidf_matrix = tfidf.fit_transform(text_list)\n",
    "    ques_tfidf_matrix = tfidf.transform(question_list)\n",
    "    sim_matrix = cosine_similarity(corpus_tfidf_matrix, ques_tfidf_matrix)\n",
    "    for ques_idx in range(sim_matrix.shape[1]):\n",
    "        dic[ques_idx] = []\n",
    "        if threshold != None:\n",
    "            for paper_idx in range(sim_matrix.shape[0]):\n",
    "                # threshold\n",
    "                score = sim_matrix[paper_idx, ques_idx]\n",
    "                if score >= threshold:\n",
    "                    dic[ques_idx].append((paper_idx, score))\n",
    "        elif top != None:\n",
    "            top_paper_idx_list = sorted(range(len(sim_matrix[:, ques_idx])), key=lambda i: sim_matrix[:,0][i], reverse=True)[:top]\n",
    "            dic[ques_idx] = [(top_idx, sim_matrix[top_idx, ques_idx]) for top_idx in top_paper_idx_list]\n",
    "        else:\n",
    "            print (\"NO!!!!!!!!!!\")\n",
    "            \n",
    "    return dic, sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_paper(df, dic):\n",
    "    for ques_idx in dic:\n",
    "        new_df = df.iloc[[item[0] for item in dic[ques_idx]], :]\n",
    "        new_df['score'] = [item[1] for item in dic[ques_idx]]\n",
    "        new_df['question'] = questions[ques_idx]\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic, sim_matrix = calc_simlarity_score(questions_cleaned, text, top=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(58526, 0.45289112747936044),\n",
       "  (35221, 0.45047275149465865),\n",
       "  (17334, 0.44869550787456114),\n",
       "  (18650, 0.44384239284923094),\n",
       "  (14308, 0.42155129141854975),\n",
       "  (7822, 0.4130088265960259),\n",
       "  (55643, 0.40191284238958536),\n",
       "  (5233, 0.3971283961214767),\n",
       "  (51504, 0.3822938315561995),\n",
       "  (56937, 0.3754049155566371),\n",
       "  (49805, 0.3709377974487783),\n",
       "  (37053, 0.3688407486815889),\n",
       "  (24196, 0.3658564069748685),\n",
       "  (40896, 0.3543083657461978),\n",
       "  (23076, 0.3508476120671627),\n",
       "  (3591, 0.34605550392399165),\n",
       "  (17278, 0.3442088296752532),\n",
       "  (49349, 0.3429517766440414),\n",
       "  (1017, 0.34172596298577324),\n",
       "  (37828, 0.33939425359022757),\n",
       "  (35537, 0.3339563602320891),\n",
       "  (15655, 0.3334758463405723),\n",
       "  (55981, 0.33091069302603515),\n",
       "  (23834, 0.3279271746419207),\n",
       "  (10740, 0.32084541695725105),\n",
       "  (58457, 0.31998343498757315),\n",
       "  (1172, 0.3155069427788312),\n",
       "  (44301, 0.3046812052557716),\n",
       "  (57041, 0.2985716798813143),\n",
       "  (25666, 0.29799089050909444),\n",
       "  (6426, 0.2978082065255916),\n",
       "  (23345, 0.2928100880919165),\n",
       "  (14032, 0.292530309989669),\n",
       "  (48406, 0.2901441352551892),\n",
       "  (27403, 0.2885186722408142),\n",
       "  (28489, 0.279566264494715),\n",
       "  (50108, 0.27762464630745637),\n",
       "  (21880, 0.27697095507989433),\n",
       "  (22262, 0.274579152145721),\n",
       "  (1688, 0.2739236093944725),\n",
       "  (11904, 0.2726696297915224),\n",
       "  (21118, 0.27096470508648673),\n",
       "  (42573, 0.26999383889557055),\n",
       "  (18349, 0.26955484752700815),\n",
       "  (18729, 0.2689570604189784),\n",
       "  (14726, 0.2650319347413304),\n",
       "  (4439, 0.2637354559289589),\n",
       "  (7716, 0.262494123018449),\n",
       "  (8673, 0.26083936112632555),\n",
       "  (2008, 0.2607640024860684),\n",
       "  (49150, 0.2592381190257696),\n",
       "  (36891, 0.2542826793432635),\n",
       "  (6711, 0.2530781926978578),\n",
       "  (50070, 0.2520799535213738),\n",
       "  (22327, 0.25203661476719824),\n",
       "  (19993, 0.24765878982467437),\n",
       "  (22204, 0.2462605081468132),\n",
       "  (17572, 0.24244307058230372),\n",
       "  (29724, 0.242256441057308),\n",
       "  (56014, 0.23988606133112275),\n",
       "  (31017, 0.2384023013888062),\n",
       "  (44064, 0.2376464254861904),\n",
       "  (4113, 0.23489826461914481),\n",
       "  (2903, 0.2326811287600812),\n",
       "  (37976, 0.23193797596743826),\n",
       "  (34752, 0.23103670810471938),\n",
       "  (54541, 0.23059030204256126),\n",
       "  (8388, 0.23035520278488392),\n",
       "  (55096, 0.22915138431184587),\n",
       "  (32405, 0.2273221353536635),\n",
       "  (30122, 0.22691781700647276),\n",
       "  (39850, 0.2253769875545013),\n",
       "  (33819, 0.22400075756517715),\n",
       "  (50372, 0.223131036511756),\n",
       "  (3706, 0.2220423541639152),\n",
       "  (43323, 0.22103385108010065),\n",
       "  (41082, 0.21967896453181543),\n",
       "  (3462, 0.21394720593225483),\n",
       "  (36082, 0.21350888336609958),\n",
       "  (50859, 0.21100370415876407),\n",
       "  (40370, 0.21035266194597485),\n",
       "  (26773, 0.2096785765709088),\n",
       "  (21911, 0.2088143994138109),\n",
       "  (10719, 0.20792766751099517),\n",
       "  (44511, 0.20605868882810485),\n",
       "  (34250, 0.2052087222601185),\n",
       "  (18056, 0.20499340526744028),\n",
       "  (17276, 0.20234791250797268),\n",
       "  (13701, 0.20127690781920513),\n",
       "  (9962, 0.20125544675887985),\n",
       "  (2502, 0.20077477524251103),\n",
       "  (30212, 0.20037667034295376),\n",
       "  (30134, 0.19707956323079362),\n",
       "  (46418, 0.19617473700763846),\n",
       "  (33030, 0.19537230092198968),\n",
       "  (14638, 0.19239699376236813),\n",
       "  (24518, 0.18958540580411132),\n",
       "  (5145, 0.18933658649708246),\n",
       "  (28201, 0.1879140111625721),\n",
       "  (32050, 0.18715376905159423)]}"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "relevant_paper = retrieve_paper(clean_pdf_df, dic)\n",
    "relevant_paper = relevant_paper.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid19_index_list = []\n",
    "for i, row in relevant_paper.iterrows():\n",
    "    text = row['text'].lower()\n",
    "    has_keyword = False\n",
    "    for keyword in keyword_list:\n",
    "        if keyword in text:\n",
    "            has_keyword = True\n",
    "            break\n",
    "    if has_keyword == True:\n",
    "        covid19_index_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_paper = relevant_paper.iloc[covid19_index_list, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_paper = relevant_paper.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relevant_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The preprocessing needs to be done before cleaning.\n",
    "relevant_paper['title_x'] = relevant_paper['title_x'].fillna(relevant_paper['title_y'])\n",
    "relevant_paper['authors_x'] = relevant_paper['authors_x'].fillna(relevant_paper['authors_y'])\n",
    "relevant_paper['abstract_x'] = relevant_paper['abstract_x'].fillna(relevant_paper['abstract_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_paper = relevant_paper.drop(['sha', 'title_y', 'authors_y', 'abstract_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_paper = relevant_paper.rename(columns={'title_x': 'title', 'authors_x': 'authors', 'abstract_x': 'abstract'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create target table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'paper_id', 'title', 'authors', 'affiliations', 'abstract',\n",
       "       'text', 'bibliography', 'raw_authors', 'raw_bibliography', 'doi',\n",
       "       'publish_time', 'journal', 'text_cleaned', 'score', 'question'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_paper.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table = pd.DataFrame(columns = ['Date', 'Study', 'Study Link', 'Journal', 'Study Type', 'Sample Size', 'Age', \n",
    "                                       'Sample Obtained', 'Asymptomatic Transmission', 'Characteristic Related to Question 2',\n",
    "                                       'Excerpt', 'Added On'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Study</th>\n",
       "      <th>Study Link</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Study Type</th>\n",
       "      <th>Sample Size</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sample Obtained</th>\n",
       "      <th>Asymptomatic Transmission</th>\n",
       "      <th>Characteristic Related to Question 2</th>\n",
       "      <th>Excerpt</th>\n",
       "      <th>Added On</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Study, Study Link, Journal, Study Type, Sample Size, Age, Sample Obtained, Asymptomatic Transmission, Characteristic Related to Question 2, Excerpt, Added On]\n",
       "Index: []"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table[['Date', 'Study', 'Journal']] = relevant_paper[['publish_time', 'title', 'journal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table['Study Link'] = \"https://doi.org/\" + relevant_paper['doi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "question = \"What's the range of the age?\"\n",
    "cnt = 0\n",
    "has_excerpt_list = []\n",
    "age_string_list = []\n",
    "age_ans_list = []\n",
    "for i, row in relevant_paper.iterrows():\n",
    "    #print (i)\n",
    "    sent_list = row['text'].split('. ')\n",
    "    ans_list = [sent for sent in sent_list if ('asymptom' in sent) & ('transmis' in sent) & ('%' in sent)]\n",
    "    age_list = [sent for sent in sent_list if (' age ' in sent.lower()) or (' aged' in sent.lower())]\n",
    "    age_string = '; \\n'.join([age for age in age_list])\n",
    "    if age_string != '':\n",
    "        age_ans = answer_question(question, age_string)\n",
    "    else:\n",
    "        age_ans = ''\n",
    "    age_string_list.append(age_string)\n",
    "    age_ans_list.append(age_ans)\n",
    "    ans_string = '; \\n'.join([ans for ans in ans_list])\n",
    "    if ans_list:\n",
    "        has_excerpt_list.append((i, ans_string))\n",
    "        cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table['Age string'] = age_string_list\n",
    "target_table['Age'] = age_ans_list\n",
    "idx_list = [item[0] for item in has_excerpt_list]\n",
    "target_table = target_table.iloc[idx_list, :]\n",
    "target_table['Excerpt'] = [item[1] for item in has_excerpt_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '\\d{2}(?:\\.\\d{1,2})?%'\n",
    "re_search = re.compile(pattern)\n",
    "re_search.findall(temp)\n",
    "\n",
    "target_table['Asymptomatic Transmission'] = target_table['Excerpt'].map(lambda x: re_search.findall(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Study</th>\n",
       "      <th>Study Link</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Study Type</th>\n",
       "      <th>Sample Size</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sample Obtained</th>\n",
       "      <th>Asymptomatic Transmission</th>\n",
       "      <th>Characteristic Related to Question 2</th>\n",
       "      <th>Excerpt</th>\n",
       "      <th>Added On</th>\n",
       "      <th>Age string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-04-18</td>\n",
       "      <td>Journal Pre-proof The relative transmissibilit...</td>\n",
       "      <td>https://doi.org/10.1016/j.ijid.2020.04.034</td>\n",
       "      <td>Int J Infect Dis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>[41.6%]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28 29 Keywords: COVID-19; asymptomatic cases; ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>Journal Pre-proof The time scale of asymptomat...</td>\n",
       "      <td>https://doi.org/10.1016/j.epidem.2020.100392</td>\n",
       "      <td>Epidemics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>[86%, 79%]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Given that 86% of the cases were undocumented ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>Asymptomatic Middle East Respiratory Syndrome ...</td>\n",
       "      <td>https://doi.org/10.1016/j.tmaid.2018.12.003</td>\n",
       "      <td>Travel Medicine and Infectious Disease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>[91%]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In a study from Abu Dhabi, of 34 casepatients,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>Public Health Policy: COVID-19 Epidemic and SE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>between 20 and 50 years old</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[40%]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>From this figure, we can conclude that the asy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[11] conclude that the contact numbers for pop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>The contribution of asymptomatic SARS-CoV-2 in...</td>\n",
       "      <td>https://doi.org/10.1101/2020.05.07.20093849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45 - 75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[53%, 56%, 83%, 69%, 74%, 69%, 85%, 56%, 76%, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We found that because systematic testing irres...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>At the start of quarantine there were 3,711 in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>The role of asymptomatic SARS-CoV-2 infections...</td>\n",
       "      <td>https://doi.org/10.1101/2020.04.25.20079103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13 months and 10 years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[60%, 90%, 47%, 95%, 58%, 57%, 60%]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In the studies included in this review, three ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5 The ages were reported for six of the asympt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>Transmission of corona virus disease 2019 duri...</td>\n",
       "      <td>https://doi.org/10.1101/2020.03.06.20031955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19 to 73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[66.2%]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Particularly, 66.2% of the secondary cases wer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We defined the back-projection equation as fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>Comparison of transmissibility of coronavirus ...</td>\n",
       "      <td>https://doi.org/10.1101/2020.04.02.20050740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>[95%, 95%, 95%]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a result, there is no evidence in the data ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>Journal Pre-proof Limited effectiveness of sys...</td>\n",
       "      <td>https://doi.org/10.1016/j.medmal.2020.04.020</td>\n",
       "      <td>Med Mal Infect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>[44%]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Second, viral transmission during the incubati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>Predicting the impact of asymptomatic transmis...</td>\n",
       "      <td>https://doi.org/10.1101/2020.04.16.20068387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>[85%, 55%, 25%, 25%]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To complicate the containment of the disease, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>Journal of Vascular and Interventional Radiolo...</td>\n",
       "      <td>https://doi.org/10.1016/j.jvir.2020.04.002</td>\n",
       "      <td>J Vasc Interv Radiol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>[50%]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The patient was subsequently referred for poly...</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                              Study  \\\n",
       "5   2020-04-18  Journal Pre-proof The relative transmissibilit...   \n",
       "6   2020-05-11  Journal Pre-proof The time scale of asymptomat...   \n",
       "7   2019-02-28  Asymptomatic Middle East Respiratory Syndrome ...   \n",
       "10  2020-04-14  Public Health Policy: COVID-19 Epidemic and SE...   \n",
       "22  2020-05-11  The contribution of asymptomatic SARS-CoV-2 in...   \n",
       "23  2020-04-29  The role of asymptomatic SARS-CoV-2 infections...   \n",
       "27  2020-03-08  Transmission of corona virus disease 2019 duri...   \n",
       "30  2020-04-07  Comparison of transmissibility of coronavirus ...   \n",
       "43  2020-05-04  Journal Pre-proof Limited effectiveness of sys...   \n",
       "58  2020-04-22  Predicting the impact of asymptomatic transmis...   \n",
       "66  2020-04-11  Journal of Vascular and Interventional Radiolo...   \n",
       "\n",
       "                                      Study Link  \\\n",
       "5     https://doi.org/10.1016/j.ijid.2020.04.034   \n",
       "6   https://doi.org/10.1016/j.epidem.2020.100392   \n",
       "7    https://doi.org/10.1016/j.tmaid.2018.12.003   \n",
       "10                                           NaN   \n",
       "22   https://doi.org/10.1101/2020.05.07.20093849   \n",
       "23   https://doi.org/10.1101/2020.04.25.20079103   \n",
       "27   https://doi.org/10.1101/2020.03.06.20031955   \n",
       "30   https://doi.org/10.1101/2020.04.02.20050740   \n",
       "43  https://doi.org/10.1016/j.medmal.2020.04.020   \n",
       "58   https://doi.org/10.1101/2020.04.16.20068387   \n",
       "66    https://doi.org/10.1016/j.jvir.2020.04.002   \n",
       "\n",
       "                                   Journal Study Type Sample Size  \\\n",
       "5                         Int J Infect Dis        NaN         NaN   \n",
       "6                                Epidemics        NaN         NaN   \n",
       "7   Travel Medicine and Infectious Disease        NaN         NaN   \n",
       "10                                     NaN        NaN         NaN   \n",
       "22                                     NaN        NaN         NaN   \n",
       "23                                     NaN        NaN         NaN   \n",
       "27                                     NaN        NaN         NaN   \n",
       "30                                     NaN        NaN         NaN   \n",
       "43                          Med Mal Infect        NaN         NaN   \n",
       "58                                     NaN        NaN         NaN   \n",
       "66                    J Vasc Interv Radiol        NaN         NaN   \n",
       "\n",
       "                            Age Sample Obtained  \\\n",
       "5                                           NaN   \n",
       "6                                           NaN   \n",
       "7                                           NaN   \n",
       "10  between 20 and 50 years old             NaN   \n",
       "22                      45 - 75             NaN   \n",
       "23       13 months and 10 years             NaN   \n",
       "27                     19 to 73             NaN   \n",
       "30                                          NaN   \n",
       "43                                          NaN   \n",
       "58                                          NaN   \n",
       "66                                          NaN   \n",
       "\n",
       "                            Asymptomatic Transmission  \\\n",
       "5                                             [41.6%]   \n",
       "6                                          [86%, 79%]   \n",
       "7                                               [91%]   \n",
       "10                                              [40%]   \n",
       "22  [53%, 56%, 83%, 69%, 74%, 69%, 85%, 56%, 76%, ...   \n",
       "23                [60%, 90%, 47%, 95%, 58%, 57%, 60%]   \n",
       "27                                            [66.2%]   \n",
       "30                                    [95%, 95%, 95%]   \n",
       "43                                              [44%]   \n",
       "58                               [85%, 55%, 25%, 25%]   \n",
       "66                                              [50%]   \n",
       "\n",
       "   Characteristic Related to Question 2  \\\n",
       "5                                   NaN   \n",
       "6                                   NaN   \n",
       "7                                   NaN   \n",
       "10                                  NaN   \n",
       "22                                  NaN   \n",
       "23                                  NaN   \n",
       "27                                  NaN   \n",
       "30                                  NaN   \n",
       "43                                  NaN   \n",
       "58                                  NaN   \n",
       "66                                  NaN   \n",
       "\n",
       "                                              Excerpt Added On  \\\n",
       "5   28 29 Keywords: COVID-19; asymptomatic cases; ...      NaN   \n",
       "6   Given that 86% of the cases were undocumented ...      NaN   \n",
       "7   In a study from Abu Dhabi, of 34 casepatients,...      NaN   \n",
       "10  From this figure, we can conclude that the asy...      NaN   \n",
       "22  We found that because systematic testing irres...      NaN   \n",
       "23  In the studies included in this review, three ...      NaN   \n",
       "27  Particularly, 66.2% of the secondary cases wer...      NaN   \n",
       "30  As a result, there is no evidence in the data ...      NaN   \n",
       "43  Second, viral transmission during the incubati...      NaN   \n",
       "58  To complicate the containment of the disease, ...      NaN   \n",
       "66  The patient was subsequently referred for poly...      NaN   \n",
       "\n",
       "                                           Age string  \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                                                      \n",
       "10  [11] conclude that the contact numbers for pop...  \n",
       "22  At the start of quarantine there were 3,711 in...  \n",
       "23  5 The ages were reported for six of the asympt...  \n",
       "27  We defined the back-projection equation as fol...  \n",
       "30                                                     \n",
       "43                                                     \n",
       "58                                                     \n",
       "66                                                     "
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the sample size?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = target_table['Excerpt'].to_list()\n",
    "sample_size_list = []\n",
    "for temp in temp_list:\n",
    "    #print (temp)\n",
    "    ans = answer_question(question, temp)\n",
    "    if not ans.isdigit():\n",
    "        ans = ''\n",
    "    sample_size_list.append(ans)\n",
    "    #print (\"Answer: \" + answer_question(question, temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_table['Sample Size'] = sample_size_list"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
