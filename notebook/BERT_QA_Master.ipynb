{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.width',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gVq-TuylYRDW"
   },
   "source": [
    "## 1. Install "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f9nhy3PzGQ44"
   },
   "source": [
    "This example uses the `transformers` [library](https://github.com/huggingface/transformers/) by huggingface. We'll start by installing the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "aQl0MMrOGIup",
    "outputId": "60e3a287-f696-429e-d65d-492e0eebd031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.9.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (2020.5.14)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (4.44.1)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.6)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.1.90)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: click in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ONLrgJK99TQ"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1WThOUtpYvG-"
   },
   "source": [
    "## 2. Load Fine-Tuned BERT-large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AaweLnNXGhTY"
   },
   "source": [
    "For Question Answering we use the `BertForQuestionAnswering` class from the `transformers` library.\n",
    "\n",
    "This class supports fine-tuning, but for this example we will keep things simpler and load a BERT model that has already been fine-tuned for the SQuAD benchmark.\n",
    "\n",
    "The `transformers` library has a large collection of pre-trained models which you can reference by name and load easily. The full list is in their documentation [here](https://huggingface.co/transformers/pretrained_models.html).\n",
    "\n",
    "For Question Answering, they have a version of BERT-large that has already been fine-tuned for the SQuAD benchmark. \n",
    "\n",
    "BERT-large is really big... it has 24-layers and an embedding size of 1,024, for a total of 340M parameters! Altogether it is 1.34GB, so expect it to take a couple minutes to download to your Colab instance. \n",
    "\n",
    "(Note that this download is not using your own network bandwidth--it's between the Google instance and wherever the model is stored on the web).\n",
    "\n",
    "Note: I believe this model was trained on version 1 of SQuAD, since it's not outputting whether the question is \"impossible\" to answer from the text (which is part of the task in v2 of SQuAD).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161,
     "referenced_widgets": [
      "549ca681c27743aa8c28af40d2185900",
      "0c5547ffbd4143609051b231a14853e1",
      "8665ab6d11084a6e980121c5475d8170",
      "461b9936e0864bc1aac73925b730ef7f",
      "49263ffffaee42438fc699c57fab7814",
      "1e6e46c1520d4a309d77a4ff7cc07900",
      "bd8a1fa1079448f585e87dafcd856bfc",
      "2b6be0f1b89044c3a934f3eccf29cf54",
      "6f9df97c25e84e7d8efccce6cde22fbc",
      "f3d792809e234442b6c888b56421479d",
      "94daf90c961945cdafc12178c3e357e4",
      "82461e6ee22b44918d424f24245bdf0e",
      "0e044677b4fc4ffe809b318e8963e08a",
      "930457a02cbe469181b0dbaf1eb9fac0",
      "e86b7da45ef6466ebf25f28c10df61b8",
      "8892ad9564d84ff190062d0a9d5d9f6f"
     ]
    },
    "colab_type": "code",
    "id": "-Mnv95sX-U9K",
    "outputId": "6df46a1c-394d-4439-91e6-9540e9cd2864"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8imoOxoqGZ0h"
   },
   "source": [
    "Load the tokenizer as well. \n",
    "\n",
    "Side note: Apparently the vocabulary of this model is identicaly to the one in bert-base-uncased. You can load the tokenizer from `bert-base-uncased` and that works just as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "632ff7bd64cf4b2c92acee6f0f17d6db",
      "87719f2515a34ba49761e7f18772a90d",
      "f6590ea2e9c14d3099b9999ce1a4602a",
      "b3e5f72146e0406d9977465e9549419f",
      "bf4308a7859f4bfd9356215bbd9ef5e4",
      "d0989443c5e84d6b8eeee08879c07db6",
      "0619db0363894129880d090367b4194a",
      "c17dfd9c89694880a04d07942db3e426"
     ]
    },
    "colab_type": "code",
    "id": "SFQ5f7gv-RBH",
    "outputId": "7e0dd1cf-b565-4c84-b377-2ebee083a9d9"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pdf_df = pd.read_csv(\"/home/ubuntu/covid19-challenge/data/clean_doc_pdf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51868, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_pdf_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the structures are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>affiliations</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "      <th>bibliography</th>\n",
       "      <th>raw_authors</th>\n",
       "      <th>raw_bibliography</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ae02f293c03e3e1a2d4582e62c22f2c0c291f48</td>\n",
       "      <td>Development of animal models against emerging ...</td>\n",
       "      <td>Troy C Sutton, Kanta Subbarao</td>\n",
       "      <td>Troy C Sutton (NIAID, NIH, United States), Kan...</td>\n",
       "      <td>Abstract\\n\\nTwo novel coronaviruses have emerg...</td>\n",
       "      <td>Introduction\\n\\nWithin the last two decades, t...</td>\n",
       "      <td>Replication and shedding of MERS-CoV in upper ...</td>\n",
       "      <td>[{'first': 'Troy', 'middle': ['C'], 'last': 'S...</td>\n",
       "      <td>{'BIBREF0': {'ref_id': 'b0', 'title': 'Replica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>640de65e9f09545c463bc419bffb7084fc40fae5</td>\n",
       "      <td>X-RAY CRYSTALLOGRAPHIC STUDIES OF THE IDIOTYPI...</td>\n",
       "      <td>Nenad Ban, Alexander Mcpherson</td>\n",
       "      <td>Nenad Ban (University of California, 92521, Ri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n1. viral: type B viral hepatitis (Kennedy ...</td>\n",
       "      <td>Three-dimensional structure of antibodies, P M...</td>\n",
       "      <td>[{'first': 'Nenad', 'middle': [], 'last': 'Ban...</td>\n",
       "      <td>{'BIBREF0': {'ref_id': 'b0', 'title': 'Three-d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  0ae02f293c03e3e1a2d4582e62c22f2c0c291f48   \n",
       "1  640de65e9f09545c463bc419bffb7084fc40fae5   \n",
       "\n",
       "                                               title  \\\n",
       "0  Development of animal models against emerging ...   \n",
       "1  X-RAY CRYSTALLOGRAPHIC STUDIES OF THE IDIOTYPI...   \n",
       "\n",
       "                          authors  \\\n",
       "0   Troy C Sutton, Kanta Subbarao   \n",
       "1  Nenad Ban, Alexander Mcpherson   \n",
       "\n",
       "                                        affiliations  \\\n",
       "0  Troy C Sutton (NIAID, NIH, United States), Kan...   \n",
       "1  Nenad Ban (University of California, 92521, Ri...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Abstract\\n\\nTwo novel coronaviruses have emerg...   \n",
       "1                                                NaN   \n",
       "\n",
       "                                                text  \\\n",
       "0  Introduction\\n\\nWithin the last two decades, t...   \n",
       "1  \\n\\n1. viral: type B viral hepatitis (Kennedy ...   \n",
       "\n",
       "                                        bibliography  \\\n",
       "0  Replication and shedding of MERS-CoV in upper ...   \n",
       "1  Three-dimensional structure of antibodies, P M...   \n",
       "\n",
       "                                         raw_authors  \\\n",
       "0  [{'first': 'Troy', 'middle': ['C'], 'last': 'S...   \n",
       "1  [{'first': 'Nenad', 'middle': [], 'last': 'Ban...   \n",
       "\n",
       "                                    raw_bibliography  \n",
       "0  {'BIBREF0': {'ref_id': 'b0', 'title': 'Replica...  \n",
       "1  {'BIBREF0': {'ref_id': 'b0', 'title': 'Three-d...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_pdf_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform text:\n",
    "Text column of a dataframe --> dictionarity (keys: paragraph name, values: content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_text_to_dict(df,col_name,output_col,print_it=False):\n",
    "    text_list=[]\n",
    "    for i in df.index:\n",
    "        line = df.loc[i]\n",
    "        text=str(line[col_name])\n",
    "        text_dict=dict()\n",
    "        comp_list= text.split(\"\\n\\n\")\n",
    "        for num in range(int((len(comp_list))/2)):\n",
    "            key_str=str(num)+'_'+str(comp_list[num*2])\n",
    "            key_str=key_str.strip()\n",
    "            text_dict[key_str]=str(comp_list[num*2+1])\n",
    "        text_list.append(text_dict)\n",
    "        if print_it ==True:\n",
    "            print(i)\n",
    "    df[output_col]=text_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_dataframe=df_text_to_dict(clean_pdf_df,\"text\",\"text_dict\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>affiliations</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "      <th>bibliography</th>\n",
       "      <th>raw_authors</th>\n",
       "      <th>raw_bibliography</th>\n",
       "      <th>text_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ae02f293c03e3e1a2d4582e62c22f2c0c291f48</td>\n",
       "      <td>Development of animal models against emerging ...</td>\n",
       "      <td>Troy C Sutton, Kanta Subbarao</td>\n",
       "      <td>Troy C Sutton (NIAID, NIH, United States), Kan...</td>\n",
       "      <td>Abstract\\n\\nTwo novel coronaviruses have emerg...</td>\n",
       "      <td>Introduction\\n\\nWithin the last two decades, t...</td>\n",
       "      <td>Replication and shedding of MERS-CoV in upper ...</td>\n",
       "      <td>[{'first': 'Troy', 'middle': ['C'], 'last': 'S...</td>\n",
       "      <td>{'BIBREF0': {'ref_id': 'b0', 'title': 'Replica...</td>\n",
       "      <td>{'0_Introduction': 'Within the last two decade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>640de65e9f09545c463bc419bffb7084fc40fae5</td>\n",
       "      <td>X-RAY CRYSTALLOGRAPHIC STUDIES OF THE IDIOTYPI...</td>\n",
       "      <td>Nenad Ban, Alexander Mcpherson</td>\n",
       "      <td>Nenad Ban (University of California, 92521, Ri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n1. viral: type B viral hepatitis (Kennedy ...</td>\n",
       "      <td>Three-dimensional structure of antibodies, P M...</td>\n",
       "      <td>[{'first': 'Nenad', 'middle': [], 'last': 'Ban...</td>\n",
       "      <td>{'BIBREF0': {'ref_id': 'b0', 'title': 'Three-d...</td>\n",
       "      <td>{'0_': '1. viral: type B viral hepatitis (Kenn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  0ae02f293c03e3e1a2d4582e62c22f2c0c291f48   \n",
       "1  640de65e9f09545c463bc419bffb7084fc40fae5   \n",
       "\n",
       "                                               title  \\\n",
       "0  Development of animal models against emerging ...   \n",
       "1  X-RAY CRYSTALLOGRAPHIC STUDIES OF THE IDIOTYPI...   \n",
       "\n",
       "                          authors  \\\n",
       "0   Troy C Sutton, Kanta Subbarao   \n",
       "1  Nenad Ban, Alexander Mcpherson   \n",
       "\n",
       "                                        affiliations  \\\n",
       "0  Troy C Sutton (NIAID, NIH, United States), Kan...   \n",
       "1  Nenad Ban (University of California, 92521, Ri...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Abstract\\n\\nTwo novel coronaviruses have emerg...   \n",
       "1                                                NaN   \n",
       "\n",
       "                                                text  \\\n",
       "0  Introduction\\n\\nWithin the last two decades, t...   \n",
       "1  \\n\\n1. viral: type B viral hepatitis (Kennedy ...   \n",
       "\n",
       "                                        bibliography  \\\n",
       "0  Replication and shedding of MERS-CoV in upper ...   \n",
       "1  Three-dimensional structure of antibodies, P M...   \n",
       "\n",
       "                                         raw_authors  \\\n",
       "0  [{'first': 'Troy', 'middle': ['C'], 'last': 'S...   \n",
       "1  [{'first': 'Nenad', 'middle': [], 'last': 'Ban...   \n",
       "\n",
       "                                    raw_bibliography  \\\n",
       "0  {'BIBREF0': {'ref_id': 'b0', 'title': 'Replica...   \n",
       "1  {'BIBREF0': {'ref_id': 'b0', 'title': 'Three-d...   \n",
       "\n",
       "                                           text_dict  \n",
       "0  {'0_Introduction': 'Within the last two decade...  \n",
       "1  {'0_': '1. viral: type B viral hepatitis (Kenn...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap_dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_ap_dataframe=ap_dataframe[[\"paper_id\",\"text_dict\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0_', '1_FabD1.3(Abl>-FabE225(Ab2) and FabD1.3-Lysozyme Complex', '2_FvD1.3(Abl)-FvE5.2(Ab2) and FabD1.3-Lysozyme complex', '3_B', '4_THE ANTI-FELINE INFECTIOUS PERITONITIS VIRUS SYSTEM', '5_Description of the Structure', '6_Idiotope-Anti-Idiotope Interface', '7_ANTI-ANGIOTENSIN II SYSTEM', '8_Number of Residues in a Loop', '9_V8 (IH)', '10_ANTI-LIPOPOLYSACCHARIDE A ANTIGEN OF BRUCELLA ABORTUS SYSTEM', '11_SELF COMPLEMENTARITY OF A MONO-CLONAL ANTIBODY GENERATED IN AN IDIOTYPIC CASCADE', '12_Structure of the Fab Fragment', '13_The Packing of the Fab Fragment and Self-Complementary Interactions', '14_Ag', '15_The Structure of the Complex', '16_The Interface between Self Complementary Antianti-idiotopes', '17_Possible Implications of the Self-Complementary Interaction'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_ap_dataframe.loc[1][\"text_dict\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51868, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_ap_dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create `appended dataframe` with `text_dict` and `paper_id` only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_df=sm_ap_dataframe[[\"paper_id\",\"text_dict\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>text_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ae02f293c03e3e1a2d4582e62c22f2c0c291f48</td>\n",
       "      <td>{'0_Introduction': 'Within the last two decade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>640de65e9f09545c463bc419bffb7084fc40fae5</td>\n",
       "      <td>{'0_': '1. viral: type B viral hepatitis (Kenn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5da136317f5b97ed8371d5121d8828f1c9a5372d</td>\n",
       "      <td>{'0_Introduction': 'Malaria is a mosquito-born...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f9ae3db6ac88670b3f47b815bb7422a75f6d47c8</td>\n",
       "      <td>{'0_Introduction': 'Nearly 3 million confirmed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a8676c57d7e3a52378b9e554cc0886ad91999e13</td>\n",
       "      <td>{'0_': 'ziektegeschiedenis Patiënt A, een 29-j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51863</th>\n",
       "      <td>7ed6060dd9d540cbf92b794305429695efb775ce</td>\n",
       "      <td>{'0_': 'The outbreak and spread of coronavirus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51864</th>\n",
       "      <td>2a35742783198a179b36b29a45fb3a7a28663026</td>\n",
       "      <td>{'0_': 'Cats have the ability to control postu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51865</th>\n",
       "      <td>d119b09f850ebbfd1fef16f22c8eec38adcc684c</td>\n",
       "      <td>{'0_| INTRODUCTION': 'In recent years, with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51866</th>\n",
       "      <td>8624ce91f316d2aae5c09273f9308cc08ffcc25c</td>\n",
       "      <td>{'0_Introduction, methods, and results': 'Porc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51867</th>\n",
       "      <td>e2445316a3475f25e869fa303d9ec90f8739d40f</td>\n",
       "      <td>{'0_': 'ular modeling tools and experimental c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51868 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       paper_id  \\\n",
       "0      0ae02f293c03e3e1a2d4582e62c22f2c0c291f48   \n",
       "1      640de65e9f09545c463bc419bffb7084fc40fae5   \n",
       "2      5da136317f5b97ed8371d5121d8828f1c9a5372d   \n",
       "3      f9ae3db6ac88670b3f47b815bb7422a75f6d47c8   \n",
       "4      a8676c57d7e3a52378b9e554cc0886ad91999e13   \n",
       "...                                         ...   \n",
       "51863  7ed6060dd9d540cbf92b794305429695efb775ce   \n",
       "51864  2a35742783198a179b36b29a45fb3a7a28663026   \n",
       "51865  d119b09f850ebbfd1fef16f22c8eec38adcc684c   \n",
       "51866  8624ce91f316d2aae5c09273f9308cc08ffcc25c   \n",
       "51867  e2445316a3475f25e869fa303d9ec90f8739d40f   \n",
       "\n",
       "                                               text_dict  \n",
       "0      {'0_Introduction': 'Within the last two decade...  \n",
       "1      {'0_': '1. viral: type B viral hepatitis (Kenn...  \n",
       "2      {'0_Introduction': 'Malaria is a mosquito-born...  \n",
       "3      {'0_Introduction': 'Nearly 3 million confirmed...  \n",
       "4      {'0_': 'ziektegeschiedenis Patiënt A, een 29-j...  \n",
       "...                                                  ...  \n",
       "51863  {'0_': 'The outbreak and spread of coronavirus...  \n",
       "51864  {'0_': 'Cats have the ability to control postu...  \n",
       "51865  {'0_| INTRODUCTION': 'In recent years, with th...  \n",
       "51866  {'0_Introduction, methods, and results': 'Porc...  \n",
       "51867  {'0_': 'ular modeling tools and experimental c...  \n",
       "\n",
       "[51868 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test sm sm df ------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_sm_df=sm_df.loc[0:10].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport time    \\n\\nstart = start = time.time()\\nwith open(\"test.txt\", \\'w\\') as f:\\n    for i in range(10000000):\\n        # print(\\'This is a speed test\\', file=f)\\n        # f.write(\\'This is a speed test\\n\\')\\nend = time.time()\\nprint(end - start)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import time    \n",
    "\n",
    "start = start = time.time()\n",
    "with open(\"test.txt\", 'w') as f:\n",
    "    for i in range(10000000):\n",
    "        # print('This is a speed test', file=f)\n",
    "        # f.write('This is a speed test\\n')\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper_id': 'c2ab03046662fc55e0162afc133b4f73ea9ed866',\n",
       " 'text_dict': {'0_': 'validation. Furthermore, similar performance was observed on the independent validation sets. We have integrated these models in the AVCpred web server, freely available at http://crdd.osdd.net/servers/avcpred. In addition, the datasets are provided in a searchable format. We hope this web server will assist researchers in the identification of potential antiviral agents. It would also save time and cost by prioritizing new drugs against viruses before their synthesis and experimental testing. ',\n",
       "  '1_R E S E A R C H A R T I C L E AVCpred: an integrated web server for prediction and design of antiviral compounds Abid Qureshi | Gazaldeep Kaur | Manoj Kumar': 'Antiviral compounds (AVCs) inhibit the development of viruses in the host cell and are relatively harmless to the host. [1] They can be natural, for example, antivirals found in turmeric [2] and eucalyptus oil, [3] or synthetic, for example, zidovudine (a nucleoside analog) [4] and Tamiflu (neuraminidase inhibitor). [5] Many compounds and drugs have also been tested and found to be useful in restricting the growth of certain viruses. [6, 7] Scientists are endeavoring to broaden the range of antivirals to other families of viruses. [8] However, designing safe and effective antiviral drugs is a difficult task due to the high genetic diversity and consequent drug resistance in viruses. [9] Initially, antivirals were discovered using traditional trial-and-error methods. [10] However, it was a very lengthy process for discovering effective antivirals. [10, 11] Later, research on virology helped to identify many target pathways to block viral multiplication. [12, 13] Scientists are now using rational drug design strategies for developing antivirals that target the viruses at different stages of their life cycles. [14] During the past decade, many new drugs have been successfully identified in controlling the viral replication in host cells, for example, maraviroc (inhibits human immunodeficiency virus or HIV entry), pleconaril (inhibits picornavirus uncoating), acyclovir (inhibits herpesvirus replication), and oseltamivir (inhibits influenza release). [9, 15] To save time and money for discovering a new drug, researchers have widely used various computational methods to screen virtual libraries of compounds before the synthesis and animal testing of chemicals. Among the different approaches, quantitative structure-activity relationship (QSAR) is mostly used. [16] [17] [18] In this approach, relationships connecting molecular descriptors and activity are used to predict the property of other molecules. [19] Molecular descriptors transform the chemical information (structure and linking of groups) of a molecule into simple numbers. [20] QSAR-based virtual screening is an effective computational technique leading toward identification and design of novel antiviral agents. [21] Lately, many dedicated bioinformatic resources have been developed for antivirals. For example, in the area of RNA interference resources published are VIRsiRNAdbantiviral siRNAs resource for about 42 disease causing viruses, [22] HIVsirDB-anti HIV siRNAs database, [23] VIRsiRNApred-antiviral siRNA inhibition efficacy predictor, [24] and VIRmiRNA-database of virus encoded miRNAs including antiviral miRNAs. [25] Similarly, for peptide-based antivirals, a few web servers have also been created like AVPdb-collection of antiviral peptides targeting more than 60 medically important viruses, [26] HIPdb-HIV inhibiting peptide repository, [27] and AVPpred-predictor of antiviral activity of peptides. [28] . Many general depositories provide information of antiviral molecules. For example, ChEMBL, [29] PubChem-a database of molecules and their activities, [30] ZINC-database of commercial compounds for virtual screening, [31] and DrugBank-a knowledgebase for drugs and drug targets. [32] In addition, there are a few QSAR studies targeting specific viral proteins. [33] [34] [35] [36] [37] [38] [39] [40] [41] However, till date there is no web server/software, which can regressively predict the percentage inhibition value of a compound against different human viruses under a single platform.To cater this need, we developed AVCpred, a web server for prediction and design of antiviral compounds. In this method, we used previously known AVCs against HIV, hepatitis C virus (HCV), hepatitis B virus (HBV), human herpesvirus (HHV) and 26 other viruses with experimentally validated percentage inhibition from ChEMBL, a large-scale bioactivity database for drug discovery. [29] This was followed by descriptor calculation and selection of best performing molecular descriptors. The latter were then used as input for support vector machine (in regression mode) to develop QSAR models for different viruses as well as a general model for other viruses. We have integrated these models in the AVCpred web server, which will be helpful for virtual screening of AVCs and designing new compounds to target the viruses.',\n",
       "  '2_| Datasets': 'In this study, we have used different datasets of AVCs having experimentally verified percent inhibition values against HIV, HCV, HHV, HBV and a general dataset having AVCs against 26 human viruses. The data were obtained from the ChEMBL resource (https://www.ebi.ac.uk/chembl/). The desired data were fetched using target browser (taxonomy tree) as well as target search using keywords such as HIV, HCV, HBV, HHV, virus, viral, viruses. Initially, among the AVCs, the majority of data belonged to HIV (1383 compounds), HCV (803 compounds), HHV (473 compounds), HBV (416 compounds), and other viruses (1635 compounds). After filtering entries with desired information and removing redundant entries, we were left with 389 compounds for HIV, 467 in case of HCV, 124 for HHV, 112 against HBV, and 1391 AVCs targeting the 26 viruses (Table 1 and Table  S1 ). These datasets were used for descriptor selection and model development. The datasets are available along with references on the web server and can be downloaded from this URL: http://crdd.osdd.net/servers/avcpred/datasets.php.',\n",
       "  '3_| Descriptor calculation': 'To develop virus specific as well as general QSAR models, we computed about 18000 chemical descriptors (1D, 2D, and 3D), including geometric, constitutional, electrostatic, topological, hydrophobic, binary fingerprints, using PaDEL, an open-source software to calculate molecular descriptors and fingerprints. [42] T A B L E 1 Creation of datasets for the development of prediction models S. no.',\n",
       "  '4_Virus Overall data': 'Data filter a Percent inhibition [1] Reference [2] Non-redundant [ The general dataset is comprised of below viruses with unique number of AVCs in brackets: Dengue virus 1, [1] dengue virus 2, [16] enterovirus, [30] human adenovirus 5, [41] human cox B1, [4] human cox B5, [21] human echovirus 13, [3] human echovirus 9, [2] human enterovirus 71, [19] human enterovirus C, [1] human polio virus 1, [4] human rhinovirus, [1] human rhinovirus 14, [29] human rhinovirus 1B, [18] human rhinovirus 2, [2] human T lymphotropic virus, [42] influenza A, [36] influenza A (H1N1), [16] influenza B, [1] monkeypox virus, [1] respiratory syncytial virus, [4] Rift Valley fever virus (Cercopithecidae), [1] sandfly fever Sicilian virus, [2] SARS coronavirus, [23] simian virus 40, [45] Sindbis virus, [4] vaccinia virus, [12] vaccinia virus WR, [22] variola virus, [1] vesicular stomatitis virus, [63] West Nile virus, [17] yellow fever virus. [51] ',\n",
       "  '5_| Feature selection': \"To improve the speed of calculation, we selected the most essential descriptors using 'RemoveUseless' filter followed by ClassifierSubsetEval (attribute evaluator) with BestFirst (search method) module available in Weka package. [43] ClassifierSubsetEval evaluates attribute subsets on training/ testing data using a classifier to estimate the merit of a set of attributes. [44, 45] The selected descriptors were then used to develop the QSAR models (Table S3 ).\",\n",
       "  '6_| Machine learning': 'We developed individual QSAR models for each of the 4 viruses (HIV, HCV, HHV, and HBV) as well as a general model comprising 26 different viruses using SMOreg algorithm [46] in Weka machine learning software [43] freely available at http://www.cs.waikato.ac.nz/ml/weka. SMOreg implements the support vector machine in regression mode. In SMOreg, Pearson VII function-based universal kernel (Puk) and RegSMOImproved optimizer were used along with parameters such as (i) the regularization constant/complexity value (c) that allows trade-off between training error and margin, (ii) the omega exponent value (ω) that controls peak half-width, and (iii) the sigma bandwidth value (σ) that controls peak tailing factor. [47, 48] Simultaneously, software SVM light (freely available at http://svmlight.joachims.org) was employed for machine learning in classification mode. In SVM light , radial basis function (RBF) kernel was used with parameters (i) gamma (g) that defines how far the influence of a single training example reaches and (ii) complexity constant (c) that allows trade-off amid training error and margin. [49] Selected molecular descriptors and fingerprints were used as input features for the development of QSAR models.',\n",
       "  '7_| Evaluation': \"In order to evaluate performance of our models, we employed a number of statistical parameters including Pearson's correlation coefficient, coefficient of determination, mean absolute error root-mean-square error, sensitivity, specificity, accuracy, and Mathew's correlation coefficient as briefly described below. The Pearson's correlation coefficient (R) is a measure of correlation between two variables.where n is the size of test set, and E i pred and E i act is the predicted and actual efficacy of AVCs respectively. A value of 1 denotes total positive correlation, 0 is no correlation, and −1 is total negative correlation.The coefficient of determination (R 2 ) indicates how well data fit a statistical model. An R 2 of 1 indicates that the model perfectly fits the data, while an R 2 of 0 means that the model does not fit the data at all.The mean absolute error (MAE) measure indicates how close the predictions are to the eventual outcomes.where E i pred is the prediction, E i act the true value, andMAEs are negatively oriented scores; that is, lower values are better.The root-mean-square error (RMSE) measures the average magnitude of the error.RMSEs are also negatively oriented scores; that is, lower values are better. Sensitivity (Sn) or the true positive rate measures the percentage of correctly identified positives.An ideal predictor would be expressed as 100% sensitive. Specificity (Sp) or the true negative rate measures the percentage of correctly identified negatives An ideal predictor would be expressed as 100% specific. Accuracy (Ac) is the percentage of correct results (i.e. both true positives and true negatives) among the total number of cases.An ideal predictor would be expressed as 100% accurate. The Matthew's correlation coefficient (MCC) is used in machine learning to evaluate the performance of binary classifications. \",\n",
       "  '8_| 77': 'Qureshi et al.In the above Eqs. (4-7) , TP, FP, TN, and FN represent the true positives, false positives, true negatives, and false negatives respectively.Its value ranges from −1 to 1 and a value close to 1 means a better prediction.',\n",
       "  '9_| Performance of QSAR models': 'In order to identify the most effective features or descriptors of antiviral drugs, we computed the correlation between selected chemical features of antiviral drugs and their percent inhibition using comprehensive pharmacological screening datasets from ChEMBL [29] (Figure 1) .After attribute selection, the relevant descriptors were 45 for HIV, 52 for HCV, 15 for HBV, 20 for HHV, and 65 for rest of the viruses. A combination of selected chemical descriptors like partial charge, atom-type electrotopological state, extended topochemical atom, chi cluster, weighted path, and fingerprints based on substructure, graph, path, and extended features including PubChem and Klekota-Roth were found to be useful in prediction. The selected descriptors were then used to develop the QSAR models (Table S3) (Table 2 ). Other statistical parameters used in the development of QSAR models are depicted in Table S2 . A scatter plot between actual and predicted efficacy in each case is shown in Figure 2 .In addition, we also checked the performance of our models developed using classification mode of machine learning. The general dataset is comprised of below viruses with unique number of AVCs in brackets: Dengue virus 1, [1] dengue virus 2, [16] enterovirus, [30] human adenovirus 5, [41] human cox B1, [4] human cox B5, [21] human echovirus 13, [3] human echovirus 9, [2] human enterovirus 71, [19] human enterovirus C, [1] human polio virus 1, [4] human rhinovirus, [1] human rhinovirus 14, [29] human rhinovirus 1B, [18] human rhinovirus 2, [2] human T lymphotropic virus, [42] influenza A, [36] influenza A (H1N1), [16] influenza B, [1] monkeypox virus, [1] respiratory syncytial virus, [4] Rift Valley fever virus (Cercopithecidae), [1] sandfly fever Sicilian virus, [2] SARS coronavirus, [23] simian virus 40, [45] Sindbis virus, [4] vaccinia virus, [12] vaccinia virus WR, [22] variola virus, [1] vesicular stomatitis virus, [63] West Nile virus, [17] yellow fever virus. [51] (ROC) plots illustrating the performance of the QSAR models are shown in Figure 3 .',\n",
       "  '10_| Web server': \"The QSAR models have been integrated into a freely available and easy to use web server, 'AVCpred', where users can predict the antiviral potential of their query molecules against the different viruses in terms of percent inhibition value. AVCpred web server includes the following modules:\",\n",
       "  '11_| Submission': 'This allows users to submit on or more molecules at a time.Users have to choose the viruses on which they want to test their query chemical compounds. On submission, it returns with percent inhibition values against the selected viruses. Also users can view the different properties of the query molecule such as structure, charge, molecular weight, logP value, hydrogen and Lipinski bond donors/acceptors, rigid and rotatable bonds to identify drug-like molecular structures ( Figure 4) . Abbreviations: Puk: Pearson VII function-based universal kernel. RegSMOImproved: optimizer for algorithm speed improvement. c: regularization constant/complexity parameter allows trade-off between training error and margin. ω: omega exponent value (controls half-width of the peak) σ: sigma bandwidth value (controls tailing factor of the peak). RBF: radial basis function g: parameter gamma in RBF kernel.',\n",
       "  '12_| Design analogs': \"It has been found that analogs of known chemical compounds are sometimes more effective than the parent molecule. [50] In order to identify potent analogs of an existing AVC, we have included the 'Design analogs' tool, where user can design analogs based on given building blocks and predict their inhibition on the viruses.\",\n",
       "  '13_| Draw structure': \"Using the 'Draw tool', one can sketch the structure of the query molecule using Marvin editor ( Figure 5 ). This tool also gives the predicted percent inhibition values against the different viruses. In addition, one can view the various properties of the query structure.\",\n",
       "  '14_| Search': 'AVCpred also provides the users a search tool to browse the compounds used in our datasets. In this module, different compounds targeting the viruses are stored in a database. The records can be readily searched, filtered/sorted, and downloaded via the web interface.',\n",
       "  '15_| Implementation': 'AVCpred has been developed using the open-source LAMP (Linux-Apache-MySQL-PHP) system. The prediction software runs on Red Hat Enterprise Linux 5 environment using Apache httpd server.',\n",
       "  '16_| DISCUSSION': 'To inhibit viral growth, the antiviral molecules or drugs target different phases of viral life cycle such as fusion, integration, replication, maturation and should be relatively non-toxic to the host organism. [51, 52] Each stage can be targeted using AVCs that can, for example, inhibit entry receptors (CD4, CCR5) or viral enzymes (protease, neuraminidase). [53] [54] [55] F I G U R E 4 AVCpred submission form with output',\n",
       "  '17_| 81': \"Qureshi et al.Various AVCs are currently in medical use, and new ones are in clinical trials. [56, 57] Finding new and improved viral inhibitors is a major concern in the treatment of deadly human viruses. [58, 59] However, discovery of novel AVCs is a tedious process. [60] To speed up the identification of new AVCs, a computational approach using QSAR method is a rational strategy to decrease cost and time efforts in the wet laboratory. [20] QSAR techniques have been widely used in drug designing and further identification of lead molecules. [17] Although there are many QSAR studies pertaining to different types of viral protein inhibitors, they are very specific in their approach and deal with a particular class of inhibitors such as endonuclease inhibitors [33] in which 40 compounds were used and reached a correlation of 0.76, thiourea derivatives [34] where 85 compounds had a correlation of 0.92, protease inhibitors [39] in which 170 compounds had a correlation of 0.60-0.83, and flavonoid inhibitors [38] where 20 compounds had a correlation of 0.75-0.97 etc. (Table 5 ). In most of the cases, the studies are carried out on a limited number of inhibitors. Due to this reason, they predict the inhibitors that are similar to the compound type with a high correlation, but do not work on other dissimilar inhibitors for the same target virus. To address these limitations, AVCpred models have been developed using diverse and large number of inhibitors. In the current algorithm, we have employed antiviral compound datasets from different studies due to which the overall correlation is less than above studies, yet the models are comparatively more robust to predict different classes of inhibitors. However, as new high-throughput screening data tested under homogeneous conditions on antiviral drugs becomes available, performance of the QSAR method can be improved.In this study, we developed virus specific as well as general prediction models to identify the likelihood of a compound being antiviral using selected chemical attributes of experimentally validated AVCs. PaDEL, an open-source software, was used to calculate molecular descriptors and fingerprints. However, the software calculates a large number of descriptors, and hence, we used attribute selection approach to reduce their number by eliminating unrelated and extraneous descriptors to get a highly correlated descriptor set. Our analysis revealed that several chemical descriptors are important in predicting the compound inhibition activity, for example, partial charge, atom-type electrotopological state, extended topochemical atom, chi cluster, weighted path, and fingerprints.We employed machine learning to train the QSAR models on different sets of experimentally validated data. These models were validated on independent datasets, not used during training, and were found to have satisfactory performance. We used the pharmacological data from the ChEMBL resource for training/testing the models developed for general as well as specific viruses. These models were integrated in an open-source web server for evaluation and screening of antiviral compounds.The applicability domain of the QSAR models was demonstrated using Williams plot ( Figure 6 ) in which [40] 9Thymidine kinase N2-phenylguanine inhibitors 20 0.85-0.98 HSV No 2000 [41] F I G U R E 5 Web interface of 'AVCpred Draw' tool standardized residuals are plotted against leverages. [61] If the standardized residual of a compound is greater than three times standard deviation units (±3σ), the compound is treated as an outlier. The warning value of leverage (h*) is considered as 3p/n, where p is the number of model descriptors plus one and n is the number of training compounds. [62, 63] If the leverage of a compound exceeds h*, it is regarded as dissident. The plots demonstrate that the leverages of majority of the compounds do not surpass the critical value (h*) in the regression models, and hence, the compounds are within the chemical domain, implying that the predictivity of the models is reliable. The web server also provides useful services like designing analogs based on given building blocks and drawing structure to sketch novel compounds and predict their inhibition potential against multiple viruses. The AVCpred algorithm is hoped to assist the researchers in discovering novel antiviral compounds as well as virtually check the effect of modifications on existing drugs.\",\n",
       "  '18_| CONCLUSIONS': 'AVCpred is the first web-based algorithm for prediction of AVCs based on experimentally validated datasets. Five prediction models pertaining to HIV, HCV, HHV, HBV, and a general one were implemented in the web server to make comprehensive predictions. In addition, tools for drug design, virtual screening, and collection of existing AVCs have also been integrated. This web server would be helpful for researchers working for the development of antiviral therapeutics.',\n",
       "  '19_ACKNOWLEDGMENTS': 'Authors are thankful to Council of Scientific and Industrial Research (CSIR) (GENESIS-BSC0121), Department of Biotechnology (GAP001), and CSIR-Institute of Microbial Technology for providing infrastructure and financial support. '}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(json.dumps(sm_sm_df.loc[5].to_dict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Json Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_sm_sm_json_line.txt\", 'w') as f:\n",
    "    for i in sm_sm_df.index:\n",
    "        json_content=json.dumps(sm_sm_df.loc[i].to_dict())\n",
    "        f.write(json_content)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Json load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_sm_sm_json_line.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        try: #print(line)\n",
    "            json.loads(line)\n",
    "            print(\"yes\")\n",
    "        except:\n",
    "            #print(line)\n",
    "            print(\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----Test_Finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Code-Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sm_ap_df_json.txt\", 'w') as f:\n",
    "    for i in sm_sm_df.index:\n",
    "        json_content=json.dumps(sm_df.loc[i].to_dict())\n",
    "        f.write(json_content)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "with open(\"test_sm_sm_json_line.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        try: #print(line)\n",
    "            json.loads(line)\n",
    "            print(\"yes\")\n",
    "        except:\n",
    "            #print(line)\n",
    "            print(\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Q_A Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, answer_text):\n",
    "    '''\n",
    "    Takes a `question` string and an `answer_text` string (which contains the\n",
    "    answer), and identifies the words within the `answer_text` that are the\n",
    "    answer. Prints them out.\n",
    "    '''\n",
    "    # ======== Tokenize ========\n",
    "    # Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "    input_ids = tokenizer.encode(question, answer_text,max_length=500\n",
    "                                )\n",
    "\n",
    "    # Report how long the input sequence is.\n",
    "    #print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
    "\n",
    "    # ======== Set Segment IDs ========\n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    # The number of segment A tokens includes the [SEP] token istelf.\n",
    "    num_seg_a = sep_index + 1\n",
    "\n",
    "    # The remainder are segment B.\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # Construct the list of 0s and 1s.\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    # There should be a segment_id for every input token.\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "    # ======== Evaluate ========\n",
    "    # Run our example question through the model.\n",
    "    start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                                    token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\n",
    "\n",
    "    # ======== Reconstruct Answer ========\n",
    "    # Find the tokens with the highest `start` and `end` scores.\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "    \n",
    "    \n",
    "    # Get the string versions of the input tokens.\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # Start with the first token.\n",
    "    answer = tokens[answer_start]\n",
    "\n",
    "    # Select the remaining answer tokens and join them with whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        \n",
    "        # If it's a subword token, then recombine it with the previous token.\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        \n",
    "        # Otherwise, add a space then the token.\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "            \n",
    "    s_scores = start_scores.detach().numpy().flatten()\n",
    "    e_scores = end_scores.detach().numpy().flatten()\n",
    "    #print('score:'+(start_scores)+\"; \"+str(end_scores))\n",
    "    #print('score:'+str(max(s_scores))+\"; \"+str(min(e_scores)))\n",
    "    #print(str(tensor[torch.argmax(start_scores)]))\n",
    "    #print('Answer: \"' + answer + '\"')\n",
    "    return [answer,str(max(s_scores)),len(input_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in clean_pdf_df.text:\\n    answer_question(\"What do we know about Hypertension?\",i)\\n'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in clean_pdf_df.text:\n",
    "    answer_question(\"What do we know about Hypertension?\",i)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_example=\"What do we know about Hypertension?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q_example_a=\"[CLS] what do we know about hypertension ? [SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm_ap_dataframe[[\"paper_id\",\"text_dict\"]].to_csv(\"sm_appended_df.csv\",sep='`', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ae02f293c03e3e1a2d4582e62c22f2c0c291f48</td>\n",
       "      <td>{'0_Introduction': 'Within the last two decade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>640de65e9f09545c463bc419bffb7084fc40fae5</td>\n",
       "      <td>{'0_': '1. viral: type B viral hepatitis (Kenn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5da136317f5b97ed8371d5121d8828f1c9a5372d</td>\n",
       "      <td>{'0_Introduction': \"Malaria is a mosquito-born...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f9ae3db6ac88670b3f47b815bb7422a75f6d47c8</td>\n",
       "      <td>{'0_Introduction': 'Nearly 3 million confirmed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a8676c57d7e3a52378b9e554cc0886ad91999e13</td>\n",
       "      <td>{'0_': 'ziektegeschiedenis Patiënt A, een 29-j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51863</th>\n",
       "      <td>7ed6060dd9d540cbf92b794305429695efb775ce</td>\n",
       "      <td>{'0_': \"The outbreak and spread of coronavirus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51864</th>\n",
       "      <td>2a35742783198a179b36b29a45fb3a7a28663026</td>\n",
       "      <td>{'0_': 'Cats have the ability to control postu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51865</th>\n",
       "      <td>d119b09f850ebbfd1fef16f22c8eec38adcc684c</td>\n",
       "      <td>{'0_| INTRODUCTION': 'In recent years, with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51866</th>\n",
       "      <td>8624ce91f316d2aae5c09273f9308cc08ffcc25c</td>\n",
       "      <td>{'0_Introduction, methods, and results': 'Porc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51867</th>\n",
       "      <td>e2445316a3475f25e869fa303d9ec90f8739d40f</td>\n",
       "      <td>{'0_': 'ular modeling tools and experimental c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51868 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0  \\\n",
       "0      0ae02f293c03e3e1a2d4582e62c22f2c0c291f48   \n",
       "1      640de65e9f09545c463bc419bffb7084fc40fae5   \n",
       "2      5da136317f5b97ed8371d5121d8828f1c9a5372d   \n",
       "3      f9ae3db6ac88670b3f47b815bb7422a75f6d47c8   \n",
       "4      a8676c57d7e3a52378b9e554cc0886ad91999e13   \n",
       "...                                         ...   \n",
       "51863  7ed6060dd9d540cbf92b794305429695efb775ce   \n",
       "51864  2a35742783198a179b36b29a45fb3a7a28663026   \n",
       "51865  d119b09f850ebbfd1fef16f22c8eec38adcc684c   \n",
       "51866  8624ce91f316d2aae5c09273f9308cc08ffcc25c   \n",
       "51867  e2445316a3475f25e869fa303d9ec90f8739d40f   \n",
       "\n",
       "                                                       1  \n",
       "0      {'0_Introduction': 'Within the last two decade...  \n",
       "1      {'0_': '1. viral: type B viral hepatitis (Kenn...  \n",
       "2      {'0_Introduction': \"Malaria is a mosquito-born...  \n",
       "3      {'0_Introduction': 'Nearly 3 million confirmed...  \n",
       "4      {'0_': 'ziektegeschiedenis Patiënt A, een 29-j...  \n",
       "...                                                  ...  \n",
       "51863  {'0_': \"The outbreak and spread of coronavirus...  \n",
       "51864  {'0_': 'Cats have the ability to control postu...  \n",
       "51865  {'0_| INTRODUCTION': 'In recent years, with th...  \n",
       "51866  {'0_Introduction, methods, and results': 'Porc...  \n",
       "51867  {'0_': 'ular modeling tools and experimental c...  \n",
       "\n",
       "[51868 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"sm_appended_df.csv\",sep='`',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blood pressure\n",
      "0.500568\n",
      "330\n",
      "excess variability\n",
      "0.032215476\n",
      "36\n",
      "analogs of known chemical compounds are sometimes more effective than the parent molecule\n",
      "0.5907004\n",
      "77\n",
      "no key lessons learned have been eliminated by merging these results .\n",
      "0.7678749\n",
      "100\n",
      "[SEP]\n",
      "0.06287956\n",
      "227\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-288-ea730d11853d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0manswer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manswer_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_example\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0ms_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manswer_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_example\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtoken_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manswer_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_example\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"[CLS]\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mQ_example_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-283-997f94ca03ff>\u001b[0m in \u001b[0;36manswer_question\u001b[0;34m(question, answer_text)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Run our example question through the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n\u001b[0;32m---> 34\u001b[0;31m                                     token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# ======== Reconstruct Answer ========\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions)\u001b[0m\n\u001b[1;32m   1446\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m         )\n\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m         )\n\u001b[1;32m    738\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             )\n\u001b[1;32m    409\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     ):\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mself_attention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add self attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         )\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in ap_dataframe.index:\n",
    "    line=ap_dataframe.loc[i]\n",
    "    dct=line[\"text_dict\"]\n",
    "    for key in dct.keys():\n",
    "        answer=answer_question(Q_example,dct[key])[0]\n",
    "        s_score=answer_question(Q_example,dct[key])[1]\n",
    "        token_len=answer_question(Q_example,dct[key])[2]\n",
    "        if (answer!=\"[CLS]\") & (float(s_score)>0) & (answer!=Q_example_a):\n",
    "            print(answer)\n",
    "            print(s_score)\n",
    "            print(token_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNRVuaKSNFG8"
   },
   "source": [
    "Just to see exactly what the tokenizer is doing, let's print out the tokens with their IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm_ap_dataframe[[\"paper_id\",\"text_dict\"]].to_json(\"sm_appended_df.json\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Question Answering with a Fine-Tuned BERT.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0619db0363894129880d090367b4194a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c5547ffbd4143609051b231a14853e1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e044677b4fc4ffe809b318e8963e08a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1e6e46c1520d4a309d77a4ff7cc07900": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b6be0f1b89044c3a934f3eccf29cf54": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "461b9936e0864bc1aac73925b730ef7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b6be0f1b89044c3a934f3eccf29cf54",
      "placeholder": "​",
      "style": "IPY_MODEL_bd8a1fa1079448f585e87dafcd856bfc",
      "value": "100% 398/398 [00:00&lt;00:00, 11.2kB/s]"
     }
    },
    "49263ffffaee42438fc699c57fab7814": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "549ca681c27743aa8c28af40d2185900": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8665ab6d11084a6e980121c5475d8170",
       "IPY_MODEL_461b9936e0864bc1aac73925b730ef7f"
      ],
      "layout": "IPY_MODEL_0c5547ffbd4143609051b231a14853e1"
     }
    },
    "632ff7bd64cf4b2c92acee6f0f17d6db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f6590ea2e9c14d3099b9999ce1a4602a",
       "IPY_MODEL_b3e5f72146e0406d9977465e9549419f"
      ],
      "layout": "IPY_MODEL_87719f2515a34ba49761e7f18772a90d"
     }
    },
    "6f9df97c25e84e7d8efccce6cde22fbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_94daf90c961945cdafc12178c3e357e4",
       "IPY_MODEL_82461e6ee22b44918d424f24245bdf0e"
      ],
      "layout": "IPY_MODEL_f3d792809e234442b6c888b56421479d"
     }
    },
    "82461e6ee22b44918d424f24245bdf0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8892ad9564d84ff190062d0a9d5d9f6f",
      "placeholder": "​",
      "style": "IPY_MODEL_e86b7da45ef6466ebf25f28c10df61b8",
      "value": "100% 1.34G/1.34G [00:33&lt;00:00, 40.4MB/s]"
     }
    },
    "8665ab6d11084a6e980121c5475d8170": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e6e46c1520d4a309d77a4ff7cc07900",
      "max": 398,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_49263ffffaee42438fc699c57fab7814",
      "value": 398
     }
    },
    "87719f2515a34ba49761e7f18772a90d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8892ad9564d84ff190062d0a9d5d9f6f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "930457a02cbe469181b0dbaf1eb9fac0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94daf90c961945cdafc12178c3e357e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_930457a02cbe469181b0dbaf1eb9fac0",
      "max": 1340675298,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e044677b4fc4ffe809b318e8963e08a",
      "value": 1340675298
     }
    },
    "b3e5f72146e0406d9977465e9549419f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c17dfd9c89694880a04d07942db3e426",
      "placeholder": "​",
      "style": "IPY_MODEL_0619db0363894129880d090367b4194a",
      "value": "100% 232k/232k [00:00&lt;00:00, 1.18MB/s]"
     }
    },
    "bd8a1fa1079448f585e87dafcd856bfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf4308a7859f4bfd9356215bbd9ef5e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c17dfd9c89694880a04d07942db3e426": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0989443c5e84d6b8eeee08879c07db6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e86b7da45ef6466ebf25f28c10df61b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3d792809e234442b6c888b56421479d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6590ea2e9c14d3099b9999ce1a4602a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0989443c5e84d6b8eeee08879c07db6",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf4308a7859f4bfd9356215bbd9ef5e4",
      "value": 231508
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
