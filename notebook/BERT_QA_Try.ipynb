{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gVq-TuylYRDW"
   },
   "source": [
    "## 1. Install "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f9nhy3PzGQ44"
   },
   "source": [
    "This example uses the `transformers` [library](https://github.com/huggingface/transformers/) by huggingface. We'll start by installing the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "aQl0MMrOGIup",
    "outputId": "60e3a287-f696-429e-d65d-492e0eebd031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: sentencepiece in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.1.90)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (4.44.1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (2020.5.14)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (2020.4.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ONLrgJK99TQ"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1WThOUtpYvG-"
   },
   "source": [
    "## 2. Load Fine-Tuned BERT-large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AaweLnNXGhTY"
   },
   "source": [
    "For Question Answering we use the `BertForQuestionAnswering` class from the `transformers` library.\n",
    "\n",
    "This class supports fine-tuning, but for this example we will keep things simpler and load a BERT model that has already been fine-tuned for the SQuAD benchmark.\n",
    "\n",
    "The `transformers` library has a large collection of pre-trained models which you can reference by name and load easily. The full list is in their documentation [here](https://huggingface.co/transformers/pretrained_models.html).\n",
    "\n",
    "For Question Answering, they have a version of BERT-large that has already been fine-tuned for the SQuAD benchmark. \n",
    "\n",
    "BERT-large is really big... it has 24-layers and an embedding size of 1,024, for a total of 340M parameters! Altogether it is 1.34GB, so expect it to take a couple minutes to download to your Colab instance. \n",
    "\n",
    "(Note that this download is not using your own network bandwidth--it's between the Google instance and wherever the model is stored on the web).\n",
    "\n",
    "Note: I believe this model was trained on version 1 of SQuAD, since it's not outputting whether the question is \"impossible\" to answer from the text (which is part of the task in v2 of SQuAD).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161,
     "referenced_widgets": [
      "549ca681c27743aa8c28af40d2185900",
      "0c5547ffbd4143609051b231a14853e1",
      "8665ab6d11084a6e980121c5475d8170",
      "461b9936e0864bc1aac73925b730ef7f",
      "49263ffffaee42438fc699c57fab7814",
      "1e6e46c1520d4a309d77a4ff7cc07900",
      "bd8a1fa1079448f585e87dafcd856bfc",
      "2b6be0f1b89044c3a934f3eccf29cf54",
      "6f9df97c25e84e7d8efccce6cde22fbc",
      "f3d792809e234442b6c888b56421479d",
      "94daf90c961945cdafc12178c3e357e4",
      "82461e6ee22b44918d424f24245bdf0e",
      "0e044677b4fc4ffe809b318e8963e08a",
      "930457a02cbe469181b0dbaf1eb9fac0",
      "e86b7da45ef6466ebf25f28c10df61b8",
      "8892ad9564d84ff190062d0a9d5d9f6f"
     ]
    },
    "colab_type": "code",
    "id": "-Mnv95sX-U9K",
    "outputId": "6df46a1c-394d-4439-91e6-9540e9cd2864"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8imoOxoqGZ0h"
   },
   "source": [
    "Load the tokenizer as well. \n",
    "\n",
    "Side note: Apparently the vocabulary of this model is identicaly to the one in bert-base-uncased. You can load the tokenizer from `bert-base-uncased` and that works just as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "632ff7bd64cf4b2c92acee6f0f17d6db",
      "87719f2515a34ba49761e7f18772a90d",
      "f6590ea2e9c14d3099b9999ce1a4602a",
      "b3e5f72146e0406d9977465e9549419f",
      "bf4308a7859f4bfd9356215bbd9ef5e4",
      "d0989443c5e84d6b8eeee08879c07db6",
      "0619db0363894129880d090367b4194a",
      "c17dfd9c89694880a04d07942db3e426"
     ]
    },
    "colab_type": "code",
    "id": "SFQ5f7gv-RBH",
    "outputId": "7e0dd1cf-b565-4c84-b377-2ebee083a9d9"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pdf_df = pd.read_csv(\"/home/ubuntu/covid19-challenge/data/clean_doc_pdf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51868, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_pdf_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the structures are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>affiliations</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "      <th>bibliography</th>\n",
       "      <th>raw_authors</th>\n",
       "      <th>raw_bibliography</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ae02f293c03e3e1a2d4582e62c22f2c0c291f48</td>\n",
       "      <td>Development of animal models against emerging ...</td>\n",
       "      <td>Troy C Sutton, Kanta Subbarao</td>\n",
       "      <td>Troy C Sutton (NIAID, NIH, United States), Kan...</td>\n",
       "      <td>Abstract\\n\\nTwo novel coronaviruses have emerg...</td>\n",
       "      <td>Introduction\\n\\nWithin the last two decades, t...</td>\n",
       "      <td>Replication and shedding of MERS-CoV in upper ...</td>\n",
       "      <td>[{'first': 'Troy', 'middle': ['C'], 'last': 'S...</td>\n",
       "      <td>{'BIBREF0': {'ref_id': 'b0', 'title': 'Replica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>640de65e9f09545c463bc419bffb7084fc40fae5</td>\n",
       "      <td>X-RAY CRYSTALLOGRAPHIC STUDIES OF THE IDIOTYPI...</td>\n",
       "      <td>Nenad Ban, Alexander Mcpherson</td>\n",
       "      <td>Nenad Ban (University of California, 92521, Ri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n1. viral: type B viral hepatitis (Kennedy ...</td>\n",
       "      <td>Three-dimensional structure of antibodies, P M...</td>\n",
       "      <td>[{'first': 'Nenad', 'middle': [], 'last': 'Ban...</td>\n",
       "      <td>{'BIBREF0': {'ref_id': 'b0', 'title': 'Three-d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id                                              title                         authors                                       affiliations                                           abstract                                               text                                       bibliography                                        raw_authors                                   raw_bibliography\n",
       "0  0ae02f293c03e3e1a2d4582e62c22f2c0c291f48  Development of animal models against emerging ...   Troy C Sutton, Kanta Subbarao  Troy C Sutton (NIAID, NIH, United States), Kan...  Abstract\\n\\nTwo novel coronaviruses have emerg...  Introduction\\n\\nWithin the last two decades, t...  Replication and shedding of MERS-CoV in upper ...  [{'first': 'Troy', 'middle': ['C'], 'last': 'S...  {'BIBREF0': {'ref_id': 'b0', 'title': 'Replica...\n",
       "1  640de65e9f09545c463bc419bffb7084fc40fae5  X-RAY CRYSTALLOGRAPHIC STUDIES OF THE IDIOTYPI...  Nenad Ban, Alexander Mcpherson  Nenad Ban (University of California, 92521, Ri...                                                NaN  \\n\\n1. viral: type B viral hepatitis (Kennedy ...  Three-dimensional structure of antibodies, P M...  [{'first': 'Nenad', 'middle': [], 'last': 'Ban...  {'BIBREF0': {'ref_id': 'b0', 'title': 'Three-d..."
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_pdf_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction\n",
      "\n",
      "Within the last two decades, there have been several introductions of zoonotic pathogens into the human population. Specifically, two novel coronaviruses (CoV), Severe Acute Respiratory Syndrome-CoV (SARS-CoV) and Middle East Respiratory Syndrome-CoV (MERS-CoV) caused significant concern because they crossed the species barrier and caused severe disease. While SARS-CoV originated in Asia and spread rapidly to several countries throughout the world, MERS-CoV has largely been restricted to infections acquired in the Middle East. Both viruses are associated with spread from person to person and a high casefatality rate, thus the development of animal models for evaluation of anti-viral therapies and vaccines has been a high priority.SARS-CoV emerged in the Guangdong province of southern China in November, 2002 (Severe acute respiratory syndrome (SARS), 2003) . Retrospective analysis identified 11 cases between November 2002 and March 2003. Of these, 7 had documented contact with wild animals (Chinese SMEC, 2004; Zhong et al., 2003; Peiris et al., 2003) . In February, 2003 an infected person traveled to Hong Kong and stayed at Hotel M (Tsang et al., 2003) . At the hotel, he spread the virus to several visitors who returned to their home countries (Canada, Ireland, the United States, Vietnam and Singapore) starting the global SARS-CoV epidemic (Peiris et al., 2003; Tsang et al., 2003; Poutanen et al., 2003; Ruan et al., 2003; Ksiazek et al., 2003) . In total, 8437 SARS-CoV cases with 813 fatalities were reported (WHO, 2003a (WHO, , 2003b . As a result of a coordinated public health effort involving screening, isolation, contact tracing and quarantine efforts, the human chain of transmission of SARS-CoV was broken (WHO, 2003a; Booth et al., 2003; Chan et al., 2003; Donnelly et al., 2003; Karlberg et al., 2004) . Since the end of the outbreak, there have been a few incidents of laboratory-acquired SARS-CoV infections (Normile and Vogel, 2003; Normile, 2004; Liang et al., 2004) , and over two weeks in December 2003 to January 2004, 4 individuals in Guangzhou, China became infected with SARS-CoV. None of these patients died from infection and the virus was not transmitted to contacts (Liang et al., 2004) . Since early 2004, SARS-CoV has not re-emerged and no new community-acquired infections have been reported. However, closely related coronaviruses have been identified in bats and at least one bat virus is able to bind the human receptor and infect human cells (Ge et al., 2013; Lau et al., 2005) .In contrast, the MERS-CoV outbreak is on-going. MERS-CoV was initially isolated from a severely ill patient in Jeddah, Saudi Arabia, in June of 2012 Bermingham et al., 2012) . Since then, there have been continued reports of new infections in geographically distinct regions suggesting separate zoonotic introductions (WHO, 2014) . Secondary transmission to health-care workers and family members has also been reported, and the WHO estimates that up to 75% of cases represent secondary infections (Al-Tawfiq and Memish, 2014) . As of early December 2014, 955 laboratory confirmed cases of MERS-CoV infection and 386 deaths have been reported (ECDC, 2014) MERS-CoV infections have been reported in at least 9 countries in the Middle East including Saudi Arabia, United Arab Emirates (UAE), Qatar, Oman, Jordan, Kuwait, Yemen, Lebanon, and Iran, and there have been isolated incidents of infected travelers returning to countries in Europe, South East Asia, and the United States (Reusken et al., 2013a (Reusken et al., , 2013b Meyer et al., 2014; Nowotny and Kolodziejek, 2014; Alagaili et al., 2014; Hemida et al., 2013; Haagmans et al., 2014; Memish et al., 2014; Azhar et al., 2014; Adney et al., 2014) .Both SARS-CoV and MERS-CoV belong to the order Nidovirales, family Coronavirus. They are both betacoronaviruses and belong to lineages B and C (Severe acute respiratory syndrome (SARS), 2003; Lau et al., 2005; Zaki et al., 2012) . As members of the Coronaviridae family, both viruses have a host cell derived lipid envelope and contain a non-segmented positive-stranded RNA genome (Masters and Perlman, 2013; van Boheemen et al., 2012) . The viral genome encodes a series of nested subgenomic RNAs that express multiple gene products. Coronaviruses attach and enter cells via interactions of the Spike (S) protein with cell surface receptors. For SARS-CoV, human Angiotensin-converting enzyme 2 (ACE2) and CD209L were identified as cellular receptors Jeffers et al., 2004) ; ACE2 is the predominant receptor as CD209L has a much lower affinity for the S protein (Jeffers et al., 2004) . The cell surface receptor for MERS-CoV is human dipeptidy peptidase 4 (hDPP4), also known as CD26 . For both SARS and MERS-CoV, the S protein host-receptor interaction is considered a major determinant of host restriction (Masters and Perlman, 2013) .Both viruses are closely related to coronaviruses identified in bats: bat-SARS-CoV from Chinese horseshoe bats and SARS-CoV (Lau et al., 2005) , and HKU4, HKU5 and MERS-CoV (Lau et al., 2005; Zaki et al., 2012) . While bats may be the primary reservoir for MERS-CoV, surveillance studies found high rates of seropositivity in dromedary camels from several Middle Eastern countries (Reusken et al., 2013a (Reusken et al., , 2013b Meyer et al., 2014; Nowotny and Kolodziejek, 2014; Alagaili et al., 2014; Hemida et al., 2013) indicating that camels play a role as a reservoir. This was strengthened by studies that identified MERS-CoV RNA in nasal swabs from 3 camels on a farm associated with 2 human cases (Haagmans et al., 2014) , and additional studies in which a camel isolate was directly linked to a fatal human case in Saudi Arabia Azhar et al., 2014) . Furthermore, experimental infection of dromedary camels demonstrated that they could be productively infected and shed high titers of virus in their nasal secretions (Adney et al., 2014) . However, the relative role of camels and bats as reservoirs for MERS-CoV remains to be determined. Under the FDA's Animal Efficacy Rule (\"Animal Rule\") therapeutics against rare, emerging, or virulent agents can achieve regulatory approval provided efficacy is demonstrated in two animal models (one of which must be a non-rodent species). Animal species of interest must first be evaluated for permissiveness to viral replication and presentation of clinical disease. As an alternative, in animal species that are permissive but do not show clinical disease, serial passage can be performed. After an animal model has been developed the resulting disease must be characterized. The ideal animal model is permissive to infection and reproduces the clinical illness and pathology observed in humans.\n",
      "\n",
      "Inoculate Species of Interest\n",
      "\n",
      "For SARS-CoV, several animal species were evaluated as models of human disease and while most laboratory animals including mice, hamsters, ferrets and non-human primates could be productively infected , few species displayed overt clinical disease. Following serial adaptation of SARS-CoV in mice (Roberts et al., 2007) and the engineering of transgenic mice to express human ACE2 (McCray et al., 2007; Yang et al., 2007) , this obstacle was partially overcome. The development of these murine models enabled efficacy studies of anti-viral agents and several vaccines against SARS-CoV (Hilgenfeld and Peiris, 2013; Graham et al., 2013) . In contrast, several animal species have been evaluated for MERS-CoV but with the exception of some primate species, most animals are resistant to infection. Herein, we describe the animal models for both SARS and MERS-CoV with a focus on the role of the host receptor. We conclude by discussing other approaches that could be used to develop animal models of MERS-CoV.\n",
      "\n",
      "Strategies for the development of animal models of infectious diseases\n",
      "\n",
      "Animal models of infectious diseases serve two key purposes: 1) to characterize viral pathogenesis, and 2) to evaluate anti-viral agents and vaccines. In the context of infectious diseases for which it is not feasible or ethical to perform clinical trials, animal studies play an additional role. Under the FDA's Animal Efficacy Rule (\"Animal Rule\") therapeutics against rare, emerging, or virulent agents can achieve regulatory approval provided efficacy is demonstrated in two animal models (one of which must be a non-rodent species) that display clinical illness representative of human disease (FDA, 2014) . The ideal animal model is permissive to infection and reproduces the clinical course and pathology observed in humans. An algorithm for the development of animal models is presented in Fig. 1 . Small animal models offer several advantages over NHPs including availability of animals and species specific reagents, ease of handling, reduced cost, and the ability to use sufficient numbers for statistical analysis. Especially with coronaviruses, rodents vary in susceptibility and may be semi-permissive to infection and refractory to clinical disease , even so, they can be used to screen countermeasures Bisht et al., 2004; Buchholz et al., 2004; . Thus, to generate a rodent model that displays clinical disease it may be necessary to adapt the virus to enhance virulence for the rodent host or generate transgenic animals. Pathogenesis in these models should be fully characterized because the disease mechanism of an adapted virus or in a transgenic animal may be different from that in the natural host ( Fig. 1) .As NHPs are closely related to humans, they are invaluable as animal models. Since studies in NHP incur significant expense, most investigators choose to screen therapies in small animal models and then perform more limited primate studies. It is important to note that there are several species and subspecies of NHP that can result in significant variation in the level of viral replication and clinical disease. Thus, several species must often be evaluated to yield a suitable animal model. Collectively, the development of animal models in both rodents and NHP has been fundamental to the study of infectious diseases and has lead to the development of countermeasures against several zoonotic pathogens.\n",
      "\n",
      "Mouse models\n",
      "\n",
      "Several inbred mouse strains have been evaluated as models for SARS-CoV infection Glass et al., 2004; Hogan et al., 2004; Wentworth et al., 2004) . Initial studies in 4-6 week old BALB/c mice demonstrated that virus doses of 10 3 and 10 5 median tissue culture infectious doses (TCID 50 ) of the Urbani strain given intranasally resulted in a productive infection with peak titers on day 3 and resolution by day 7. Mice did not lose weight, display signs of clinical disease or develop pulmonary pathology. Studies in C57BL/6 (B6) mice yielded similar results, with a lack of clinical disease and clearance of virus by day 9. Knockout mice on the B6 background including beige and CD1 À / À strains that lack NK cell function and NK-T cells, respectively, and RAG1 À / À mice that lack T and B lymphocytes also did not develop clinical disease. Viral kinetics were similar in B6, beige, CD1 À / À mice, and RAG1 À / À mice (Glass et al., 2004) . Similarly, 129SvEv mice displayed peak viral replication on day 3 with clearance by day 8 and did not develop clinical illness. Histopathological examination showed evidence of self-limiting bronchiolitis and patchy interstitial pneumonia. In contrast, disease progression was significantly altered in STAT1 À / À mice on the 129SvEv background. STAT1 À / À mice displayed progressive weight loss and bronchiolitis that progressed to interstitial pneumonia and mediastinitis . Viral replication peaked on day 3 and persisted until day 22 post-infection indicating that a type I IFN response is required to control SARS-CoV infection. Although mice showed evidence of infection and lung disease, inbred mouse strains did not accurately reproduce the diffuse alveolar damage, edema, pneumocyte necrosis, and hyaline membrane formation observed in humans (Ding et al., 2003; Franks et al., 2003; Nicholls et al., 2003) .To model the epidemiological finding that advanced age resulted in increased mortality, an aged mouse model of SARS-CoV was developed. In this model, 12-14 month old BALB/c and B6 mice support high levels of viral replication in the lungs from day 2 to 6 with resolution by day 9. Both strains of mice lose weight ( $7-8% on day 5) and aged BALB/c mice displayed ruffled fur and dehydration (Roberts et al., , 2005b . In contrast, aged 129SvEv mice did not support prolonged pulmonary viral replication and cleared the virus by day 5 . Regardless, all aged mouse strains displayed similar histopathological features early during infection (i.e. day 3) including perivascular and peribronchiolar mononuclear infiltrates, necrotic debris in the bronchioles, and foci of interstitial pneumonitis (Roberts et al., , 2005b . On day 5 post-infection, aged BALB/c mice displayed prominent perivascular infiltrates and alveolar damage that persisted until day 9 (Roberts et al., 2005b) . Collectively, the pathological changes observed in the aged mouse model more closely resemble those observed in humans and as a result aged mice have been used more extensively than young mice.To develop a mouse model of SARS-CoV infection with associated mortality, transgenic mice expressing human ACE2 have been generated (McCray et al., 2007; Yang et al., 2007; Netland et al., 2008; Tseng et al., 2007) . In general, disease severity in transgenic mice correlated with the level of hACE2 expression. Transgenic mice expressing hACE2 under the control of a cytokeratine promoter had high levels of ACE2 mRNA in the lung, liver, colon, and kidney (McCray et al., 2007; Netland et al., 2008) . When these mice were challenged with SARS-CoV, they developed a severe infection beginning in the airway epithelium that spread to the brain. Infection resulted in weight loss beginning between days 3 and 5, and 100% mortality by day 7 (McCray et al., 2007; Netland et al., 2008) . Using an alternate approach in which hACE2 was expressed under the control of a chicken beta-actin promoter with an cytomegalovirus IE enhancer, transgenic mouse lines with differing levels of hACE2 were generated (Tseng et al., 2007) . Infection of mice with high levels of hACE2 expression similarly yielded a severe lung and brain infection with 100% mortality. In contrast, infection of mice expressing lower levels of hACE2 resulted in clinical illness without associated mortality (Tseng et al., 2007) . This finding was further supported by a third model in which hACE2 was expressed under the control of the mouse ACE2 promoter resulting in limited tissue distribution of hACE2. When these mice were challenged with SARS-CoV, they became lethargic but survived infection (Yang et al., 2007) . These mice also showed severe interstitial pneumonia with extrapulmonary organ damage suggesting that they more accurately modeled human SARS-CoV infection. However, in all of these studies, an increase in viral load or viral antigen was observed in the brain tissue of transgenic mice, and mortality resulted from extensive dissemination of the virus in the brain (McCray et al., 2007) . This finding is in contrast to human disease in which central nervous system infection was only rarely observed. Thus, while transgenic mice resulted in a lethal model of SARS-CoV infection, no mouse model accurately reproduced the disease spectrum observed in SARS-CoV infected patients.Both wild-type mice and knockout strains have been evaluated as models of MERS-CoV infection (Coleman et al., 2014a) . In these studies, eight week-old BALB/c, 129SvEv, and 129SvEv STAT1 À / À mice were intranasally inoculated with 120 or 1200 TCID 50 of EMC-2012. None of the mice lost weight or developed clinical signs, and all of the mice survived challenge. On days 2 and 4 postinfection, lungs were harvested and viral load was assayed by titration on Vero cells or by qRT-PCR. RT-PCR analysis for genomic RNA indicated that the virus was present on day 2; however, no subgenomic mRNA transcripts, indicative of active replication, were detected and replicating virus could not be cultured from lung homogenates. Furthermore, mice did not develop pulmonary pathology (Coleman et al., 2014a) . Analysis of the MERS-CoV host receptor (DPP4) expression by immunohistochemistry and RT-PCR indicated that low levels of DPP4 were expressed in the lungs (Coleman et al., 2014a) , and early studies on the binding efficiency of MERS-CoV S protein RBD to mouse cells (LR7 cell line) showed low binding efficiency (Raj et al., 2013, Table S1) . Collectively, these studies demonstrated that mice are naturally non-permissive to MERS-CoV and inbred strains do not represent a suitable small animal model.\n",
      "\n",
      "Syrian hamster model\n",
      "\n",
      "Golden Syrian hamsters are highly permissive to SARS-CoV infection (Roberts et al., , 2005a Lamirande et al., 2008) . Infection of hamsters with SARS-CoV (10 3 or 10 5 TCID 50 of the Urbani strain) results in a productive infection with peak replication on day 2-3 in the nasal turbinates and lungs, and viral clearance by day 7. Infection also results in extrapulmonary spread consisting of transient viremia and spread to the liver and spleen in a proportion (1/3 or 2/3) of animals. Viral replication is accompanied by pulmonary histopathology consisting of focal areas of interstitial inflammation and consolidation that are visible on day 3, and become more widespread until day 7 when consolidation involves 30-40% of the lung (Roberts et al., 2005a) . Despite the extensive pulmonary pathology, hamsters do not display overt clinical disease or mortality. Weight loss is difficult to assess in hamsters due to the storage of food in large cheek pouches; however, the use of a running wheel with a rotation counter permitted objective measurement of nocturnal activity of these animals. Compared to mock-infected hamsters and preinfection activity levels, SARS-CoV infected hamsters exhibited a greater than 90% reduction in activity Lamirande et al., 2008) . This was the first objective measurement of clinical illness in hamsters.In subsequent studies, hamsters were also shown to be susceptible to several different strains of SARS-CoV . These strains included Urbani, HKU-39849, Frankfurt 1, and a recombinant clone GD03T0013. Infection with Frk-1 resulted in limited mortality in 3 of 20 animals, while all other strains did not produce a lethal infection. Collectively, these studies demonstrate that the hamster represents a suitable model of SARS-CoV infection; although much like the young and aged mouse models, mortality was not a prominent feature of the model (Liang et al., 2005; Watts et al., 2008) .Based on the success of hamsters as a model for SARS-CoV, they were similarly evaluated as a model of MERS-CoV infection (de Wit et al., 2013b) . Syrian hamsters were given either 10 3 or 10 6 TCID 50 of EMC-2012 by intratracheal inoculation or 4 Â 10 2 TCID 50 via aerosol. Animals were monitored for clinical disease, and nasal, oropharyngeal, urogenital, and rectal swabs were collected daily from days 1 to 11 post-infection. Inoculated animals did not display clinical signs or weight loss, and all swabs were negative for viral RNA by qRT-PCR (de Wit et al., 2013b) . Tissues were collected on days 2, 4, 8, 14, and 21 post-infection. On days 2, 4, and 8, vRNA could not be detected in the lungs, spleen, or mandibular lymph nodes by qRT-PCR, and no significant histopathology was observed in the lungs, trachea, kidney, and brain. To further determine if the hamsters had been infected, Mx gene expression was assayed as an indicator of an innate immune response. In MERS-CoV inoculated animals, Mx expression was similar to that of mock-infected infected animals. To verify that the host receptor of MERS-CoV was expressed in hamsters, immunohistochemistry for DPP4 was performed. DPP4 was expressed at high levels in bronchiolar epithelium and smooth muscle in the lung, and also in the glomerular parietal epithelium and nerve tissue in the kidney (de Wit et al., 2013b) . Collectively, these results indicate that similar to mice, hamsters are not permissive to MERS-CoV; however, in contrast to mice, hamsters do show high levels of DPP4 expression.\n",
      "\n",
      "Ferret model\n",
      "\n",
      "Ferrets represent an excellent model of influenza infection and as a result were evaluated for susceptibility to SARS-CoV. Infection of ferrets with virus doses from 10 3 to 10 7 TCID 50 yielded a productive infection in lungs, trachea and nasal turbinates. Viral replication peaked in the lungs on day 5 or 6, and reached levels of 10 6 TCID 50 /mL of lung homogenate (Chu et al., 2008; Martina et al., 2003; ter Meulen et al., 2004; Weingartl et al., 2004) . The primary histopathological finding was of multifocal pulmonary lesions affecting 5-10% of the lung with mild alveolar damage, and peribronchiolar and perivascular lymphocyte infiltration ( Reports on clinical disease vary. In initial studies utilizing intratracheal administration, 3 of 6 infected ferrets became lethargic and one animal succumbed to disease, and in a study utilizing the Toronto-2 (Tor2) SARS-CoV isolate, lethargy and prolonged disease was also observed (Martina et al., 2003; Kobinger et al., 2007) . In subsequent reports using either intratracheal or intranasal administration lethargy or mortality were not observed (Chu et al., 2008; ter Meulen et al., 2004; Weingartl et al., 2004; Darnell et al., 2007) . Furthermore, in a study specifically designed to assess the ferret as a non-rodent model to meet the criteria for the FDA \"Animal Rule\", clinical disease was limited to fever and sneezing in large groups of ferrets inoculated with the Toronto-2 strain (Chu et al., 2008) . In a single study, contact transmission of SARS-CoV to uninfected cage mates was reported along with conjunctivitis and mortality on days 16 and 21 (Martina et al., 2003) . Histopathological analysis found evidence of hepatic lipidosis and emaciation indicating mortality was not associated with SARS-CoV pneumonia. These findings indicate that SARS-CoV could transmit at low levels by direct contact in the ferret model. In summary ferrets were shown to support SARS-CoV replication with varying degrees of clinical disease, and much like the rodent models, SARS-CoV infection did not result in significant mortality.To potentially overcome host factors that may limit infection in rodents, ferrets were evaluated as a model for MERS-CoV . Four animals were inoculated intranasally and intratracheally with 1 Â 10 6 TCID 50 of EMC-2012. Nasal and throat swabs were collected at intervals from 1 to 14 days postinfection and assayed for viral replication. Virus was not recovered from the swabs and qRT-PCR analysis demonstrated that low levels of viral RNA were present only on days 1 and 2 postinfection . Ferrets also failed to seroconvert, further evidence that the animals had not been infected. In subsequent experiments, primary ferret kidney cells were shown to be resistant to MERS-CoV infection despite high levels of DPP4 expression. Transfection of an expression plasmid for human DPP4 into primary ferret kidney cells rendered the cells susceptible to MERS-CoV infection, demonstrating that ferret DPP4 was the major host restriction factor. Further in vitro experiments with chimeric human-ferret DPP4 constructs demonstrated that the DPP4 receptor-binding domain (RBD) was responsible for the relative resistance or susceptibility of ferret cells to infection with MERS-CoV . These findings demonstrate that ferrets, like hamsters and mice, are not a suitable as a model of MERS-CoV infection.\n",
      "\n",
      "Non-human primate models\n",
      "\n",
      "Six NHP species have been evaluated as models of SARS-CoV infection. These include three Old World Monkeys: rhesus and cynomolgus macaques, and African Green monkeys, and three New World Monkeys: common marmoset, squirrel monkeys, and mustached tamarins Lawler et al., 2006; Fouchier et al., 2003; Roberts and Subbarao, 2006; McAuliffe et al., 2004; Rowe et al., 2004; Qin et al., 2005; Rockx et al., 2011; Greenough et al., 2005) . With the exception of squirrel monkeys and mustached tamarins (Roberts and Subbarao, 2006) , all NHPs examined support SARS-CoV replication. Initial studies were performed in cynomolgus macaques to demonstrate that SARS-CoV fulfilled Koch's postulates. In these studies, virus was isolated from nasal secretions, and virus could be detected in lung samples by RT-PCR. Consistent with virus isolation, the animals had pulmonary pathology indicative of interstitial pneumonia and representative of mild human disease. In these and other studies using cynomolgus macaques a range of clinical illness has been reported with observations ranging from skin rash, decreased activity, cough, and respiratory distress, to an absence of clinical disease (Lawler et al., 2006; McAuliffe et al., 2004; Rowe et al., 2004; Rockx et al., 2011) .To compare Old World monkey species, African Green monkeys, cynomolgus, and Rhesus macaques were challenged in parallel with SARS-CoV Urbani strain. No animals developed clinical disease and all three species had viral replication in combined nasal-throat swabs, and in tracheal lavage samples . Viral replication was highest in African Green monkeys, followed by cynomolgus and then Rhesus macaques. Viral titers peaked by day 2 with clearance in the upper and lower respiratory tract by days 8 and 10, respectively. All three species produced neutralizing antibodies and antibody titers correlated with virus replication. Pulmonary pathology was examined in African Green monkeys on days 2 and 4 post-infection. Consistent with the features of interstitial pneumonia, on day 2 there were focal interstitial mononuclear inflammatory infiltrates and edema in the lung. Staining for viral antigen identified type 1 pneumocytes as the predominant cell type infected by SARS-CoV, and on day 4 there was a reduction in the amount of viral antigen and level of inflammation . In a subsequent study on Rhesus macaques challenged with the SARS-CoV PUMC01 strain, virus could be detected in nasal and pharyngeal swabs, and on days 5 and 7 pulmonary histopathology was similarly consistent with interstitial pneumonia (Qin et al., 2005) .Infection of common marmosets also resulted in mild clinical disease with $ 50% of animals developing a febrile response and diarrhea (Greenough et al., 2005) . Due to technical challenges, replicating virus could not be isolated from lung homogenates; however, high levels of vRNA were detected in lung samples on both days 4 and 7 post-infection. Marmosets developed both pulmonary and hepatic pathology with evidence of interstitial pneumonitis at all time points (days 2, 4, and 7). Hepatic lesions started to develop on day 2 and were readily apparent in 4 of 5 animals on day 4. On day 7 all animals had evidence of multifocal hepatitis. Hepatic lesions were also observed in human patients and the marmoset was the only NHP to develop liver disease (Greenough et al., 2005) . Collectively, the NHP species that were permissive to SARS-CoV infection modeled differing aspects of human disease with African Green monkeys supporting high levels of replication in the respiratory tract and marmosets modeling hepatic pathology. All species showed evidence of interstitial pneumonia, however, no species consistently reproduced severe clinical disease and mortality was not observed in any species.Two species of NHP have been evaluated as models of MERS-CoV infection. These include the rhesus macaque and common marmoset (de Wit et al., 2013a; Falzarano et al., 2014; Munster et al., 2013; Yao et al., 2014) . Both species are susceptible to MERS-CoV infection; however, the extent of replication and disease severity vary. Upon a combined intranasal, intratracheal, oral and ocular inoculation with 1 Â 10 7 TCID 50 EMC-2012 strain, Rhesus macaques develop mild clinical signs consisting of decreased food intake, nasal swelling, increased respiratory rate, and elevated white blood cells counts early after infection (days 1-2 p.i.) (de Wit et al., 2013a; Munster et al., 2013) . All animals survived until the designated endpoint of day 6 post-infection. vRNA was detected in nasal swabs on days 1 and 3, and in most animals was cleared by day 6. Replicating virus could be recovered from lung tissue (Munster et al., 2013) and titers decreased from day 3 to 6 post-infection. Examination of viral dissemination throughout the respiratory tract by qRT-PCR demonstrated that vRNA could be detected in the nasal mucosa, trachea, mediastinal lymph nodes, conjunctiva, oronasopharynx, and bronchi on day 3. Viral loads decreased by day 6 and vRNA could not be detected in the nasal mucosa and conjunctiva at this later time point (de Wit et al., 2013a) . Gross examination of multiple organs on day 3 and 6 revealed that pathology was restricted to the lungs with 0-75% of each lung lobe containing lesions. Consistent with this observation, vRNA could not be detected in the kidney or bladder. Further histopathological analysis found that animals displayed mild to marked interstitial pneumonia on day 3 that progressed to abundant alveolar edema and formation of hyaline membranes on day 6 (de Wit et al., 2013a; Munster et al., 2013) .In an analogous study, four Rhesus macaques were intratracheally inoculated with 6.5 Â 10 7 TCID 50 of EMC-2012. Two animals were maintained for 28 days and two animals were necropsied on day 3 p.i. All of the animals showed an increase in temperature on days 1-2, had reduced water intake, and survived the infection. RNA was not detected in nasal, oropharyngeal, and cloacal swabs collected at regular intervals. Radiographic imaging on days 3 and 5 showed interstitial infiltrates indicative of pneumonia, and replicating virus was isolated from lung samples on day 3. Virus could not be isolated from any other tissue including trachea, brain, and kidney (Yao et al., 2014) . Similar to the previous study, gross examination revealed lesions restricted to the lung, and microscopic analysis showed multifocal mild to moderate interstitial pneumonia. Animals also developed serum neutralizing antibody responses that were detected on day 7, peaked on day 14 (1:320) and remained elevated at day 28 (1:160) (Yao et al., 2014) .Taken together, these studies show that infection of Rhesus macaques with MERS-CoV results in a transient lung infection with associated pneumonia. The discrepancies in the extent of virus replication in the respiratory tract, observations of nasal swelling, and isolation of virus from nasal swabs most likely reflect the use of multiple inoculation routes in the earlier studies. Animals showed mild clinical disease early during infection and mortality was not observed. Thus, Rhesus macaques do not recapitulate the severe infection observed in human cases; however, IFN-α and ribavirin were evaluated in this model and were shown to limit infection (Falzarano et al., 2013) .Based on modeling of MERS-CoV S protein-DPP4 interactions, the common marmoset was evaluated as model of MERS-CoV (Falzarano et al., 2014) . To recapitulate severe disease marmosets were given a total of 5.2 Â 10 6 TCID 50 of EMC-2012 via a combination of intranasal, oral, ocular, and intratracheal routes. Clinical disease ranged from moderate to severe, with animals showing increased respiratory rate, decreased body temperature, loss of appetite, and decreased activity. Peak clinical illness was observed between days 4 and 6, and 2 of nine animals were euthanized due to severe disease. Radiological evaluation revealed evidence of moderate to severe interstitial infiltration in both lower lung lobes on day 3 and 6; by day 9 the remaining animals had reduced infiltration indicative of recovery. On day 1 all throat swabs and 8/9 nasal swabs were positive for vRNA. Viral load in the nose and throat swabs decreased by day 3, but vRNA was consistently isolated from throat swabs in a proportion of animals as late as 13 days post-infection. In the respiratory tract, vRNA could be detected from days 2-6 in the conjunctiva, nasal mucosa, trachea, mediastinal lymph node, and all lung lobes. In addition, two animals showed evidence of viremia with vRNA detected in the blood and vRNA was detected in multiple organs including the kidney, liver, and heart, indicating systemic dissemination of the virus. However, given that the animals were inoculated via multiple routes this may have facilitated systemic infection and spread throughout the respiratory tract.Histopathological analysis on day 3 revealed acute bronchointerstitial pnemonia with viral antigen present in regions of pathological change. By day 6, acute pneumonia was still prominent, with type II pneumocyte hyperplasia and consolidation of pulmonary fibrin resulting in hyaline membrane formation. Consistent with the severe lung infection, type I pneumocytes, bronchiolar epithelial cells, and smooth muscle cells were all found to express DPP4 (Falzarano et al., 2014) . Thus, the common marmoset reproduces several features of MERS-CoV infection, and can potentially be used to evaluate novel therapies for human use.\n",
      "\n",
      "Role of ACE2 in animal models of SARS-CoV infection\n",
      "\n",
      "ACE2 was identified as the functional receptor for SARS-CoV in African Green monkey derived Vero E6 cells . Subsequent crystallography studies identified 14 amino acid positions in ACE2 that have direct contact with the S protein receptorbinding domain (RBD) (see Table 1 ) (Li et al., 2005a) . As civet (c) ACE2 displayed affinity for both human (Tor2 and GD03) and civet SARS-CoV isolates (Sz02 and Gd05), while human (h) ACE2 preferentially bound the S protein RBD of human isolates, biochemical studies were performed to define mutations influencing RBD affinity (Li, 2008; Wu et al., 2012 Wu et al., , 2011 Li et al., 2005b) . These studies identified two regions of interaction between the S protein RBD and ACE2 at which mutations evolved to accommodate a switch in preference from cACE2 to hACE2 (Li, 2008; Wu et al., 2012 Wu et al., , 2011 . The two regions were designated hotspot 31 and hotspot 353. In hotspot 31, residues K31 and E35 of hACE2 interact to form a salt bridge, and E35 in turn interacts with N479 of the S protein RBD. In contrast, the RBD of civet isolates has a 479K mutation and this lysine residue competes with E35 of hACE2 destabilizing the salt bridge and diminishing binding. To compensate, civet ACE2 has a Threonine (T) at position 31. This removes the salt bridge structure and the destabilizing effect of 479K, permitting high affinity binding (Li, 2008) .The interaction of amino acids at or near position 353 of ACE2 was also found to play a significant role in RBD-ACE2 affinity. Both hACE2 and cACE2 have lysine (K) at position 353, and in hACE2 K353 interacts with aspartate (D) 38 to form a second salt bridge. Formation of this bridge requires additional support from threonine (T) 487 from the S protein RBD of human SARS-CoV strains. In civet isolates, there is a serine (S) at position 487 that does not support the formation of a salt bridge with D38, resulting in decreased affinity for hACE2. In cACE2 position 38 encodes a glutamate (E) that has a longer side chain than aspartate. This allows E38 to support the formation of a salt bridge in the absence of T487 and promotes binding of the civet isolates to cACE2 (Li, 2008) .In the context of animal models of SARS-CoV infection, the interactions of the S protein RBD at these hot spots may partially explain the varying levels of replication observed in different species. In Table 1 , we have compared the ACE2 amino acids that interact with the S protein RBD from several species. Examining the human, AGM, and macaque ACE2 residues, all 4 species have identical RBD-ACE2 interaction residues. The marmoset and hamster ACE2 residues are very similar to those of hACE2 and this is in agreement with the permissive nature of these species. In contrast, many of the residues of mouse ACE2 are different from those of human ACE2 (Li et al., 2005a) and this corresponds with reduced replication of SARS-CoV in mouse cells (Li et al., 2004) and the lungs of young mice . While mice are semi-permissive to SARS-CoV, rats do not support replication of SARS-CoV. Two changes relative to human ACE2, at positions 353 and 82 of mouse and rat ACE2 are predicted to account for this difference in replication (Li et al., 2005a) . Both mice and rats have a histidine at position 353 compared to 353K in hACE2. This partially disrupts the S protein-DPP4 interaction (Li et al., 2005a) ; moreover, the asparagine (N) 82 of rat ACE2 introduces a glycosylation site that blocks the interaction at position 82 with residue L472 of the S protein RBD. In contrast, mouse ACE2 has a serine (S) at position 82, that though sub-optimal, does not prevent the interaction with the S protein. Together the combined changes in mACE2 at position 353 and 82 lead to inefficient binding of the S protein and reduced permissiveness of mouse cells, while the glycosylation site at residue 82 in rat ACE2 abrogates binding (Li et al., 2005a) .Examination of the hamster ACE2 sequence at position 82 also reveals an asparagine (N) residue and examination of the surrounding amino acid residues indicates the presence of a glycosylation site. This is surprising as hamsters are highly permissive to SARS-CoV; however, the inhibitory effect of N82 may be overcome by the multiple additional interactions (i.e. K353) that are shared by human and hamster ACE2. It is tempting to speculate that hamsters may have developed lethal or more pronounced clinical disease if the amino acid residue at position 82 had been similar to that of hACE2.Of interest, most of the ferret ACE2 interaction residues are different from those of hACE2; thus it is surprising that ferrets are permissive to SARS-CoV infection. Comparing civet and ferret ACE2, many of the residues are the same, and experimental studies have shown that civets can be infected with human isolates (Wu et al., 2005) . Thus, while the ferret ACE2 may be different from hACE2, the similarity with cACE2 may result in affinity between ferret ACE2 and the S protein RBD permitting infection and replication.In summary, the structural analysis of ACE2-S protein interactions agree with observations of improved replication in several animal models. However, this finding does not fully explain the host restriction and limited clinical disease observed in animal models. Despite high degrees of similarity between NHP ACE2 sequences and hACE2, NHPs do not recapitulate human disease and within the NHP species there is variation in the level of viral replication. Furthermore, aged mice develop disease and support replication despite reduced affinity of mACE2 for the S protein RBD. Thus, while it is clear the interaction of ACE2 with the S protein-RBD is required for efficient infection and replication, additional host factors likely also contribute to the development of severe disease.\n",
      "\n",
      "Mouse-adaptation of SARS-CoV\n",
      "\n",
      "As an alternative to evaluating multiple animal species, another strategy to generate an animal model with clinical disease is to adapt the virus to the new host by serial passage (Fig. 1) . To generate a mouse model with associated mortality, the SARS-CoV Urbani strain was serially passaged in the lungs of young BALB/c mice (Roberts et al., 2007) . After 15 passages, a single virus clone was isolated that caused 100% mortality in young (6-8 week old), 4 week old, and aged BALB/c mice. This virus was designated Sites that play an important role in host range and cross species infection are indicated in bold type and are underlined. MA15. Severe disease was the result of an overwhelming viral infection with significantly higher titers and prolonged replication in the lungs accompanied by extensive damage to bronchiolar and alveolar epithelial cells (Roberts et al., 2007) . MA15 was also capable of extrapulmonary spread as evident by viremia, and recovery of virus from spleen, liver, and brain tissues. Sequence analysis and reverse genetics studies identified 6 amino acid mutations associated with the lethal phenotype. These mutations included 3 changes in ORF1a, and single changes in ORF1b, the M protein, and the S protein. Of particular interest, the mutation in the S protein Y436H was located in the S protein RBD. In follow-up studies, the relative contribution of each mutation in MA15 was defined using a panel of recombinant viruses (Frieman et al., 2012) . Reversion of four mutations did not alter virulence, however, reversion of the nsp9 (located in ORF1a) or S protein mutations resulted in reduced weight loss from 420% to 10-20% and less than 5% for the nsp9 and S protein mutations, respectively. Furthermore, reversion of the S protein mutation resulted in a non-lethal infection with no clinical disease. Introduction of the S protein and nsp9 mutations either alone or combined into the Urbani infectious clone failed to induce a lethal infection in young BALB/c mice indicating that the S protein and nsp9 mutations were necessary but not sufficient to induce severe disease. Given that 6 mutations were present in MA15, the additional mutations in ORF1a, ORF1b, and the M gene may have lead to enhanced disease by promoting interactions with host cell proteins involved in viral replication (Frieman et al., 2012; Zornetzer et al., 2010) . Alternatively, these mutations may also alter the host response as STAT À / À mice progressed more rapidly to a terminal endpoint when inoculated with MA15 compared to wild-type virus .To develop additional mouse-adapted virus strains, the Urbani strain was similarly passaged 20 or 25 times in two separate studies to yield lethal virus strains termed MA20 and Strain v2163 (Frieman et al., 2012; Day et al., 2009) . In a direct comparison with MA15, infection with Strain v2163 resulted in significantly higher pulmonary virus titers and enhanced mortality at lower doses. Ten amino acid changes in v2163 were associated with adaptation and 4 mutations arose in the S protein. More specifically, Y436H and a second mutation at Y442F were identified in the RBD. An additional mutation K411E in the RBD was found in some samples, but was not found in the lungs of infected mice. The two remaining S protein mutations were T1118I and N1169D and were located outside the RBD in the S2 heptad repeat elements (Day et al., 2009) . Sequencing of the MA20 strain revealed 6 amino acid mutations with two changes in the S protein binding domain: Y442L and N479K (Frieman et al., 2012) .The changes that arose during mouse adaptation in the S protein RBD are predicted to enhance affinity or binding of the S protein to mACE2. In human SARS-CoV strains, residue Y436 of the S protein interacts with hACE2 at residues D38 and Q42. This interaction is within hotspot 31 and binding is further influenced by residue 353K of hACE2. In mACE2 the K353H mutation interferes with the interaction between Y436 of the S protein RBD and D38 of mACE2. Thus, in MA15, the mutation Y436H that arose with serial passage overcomes this interference (Frieman et al., 2012) promoting enhanced binding. In the MA20 strain, two mutations evolved in the RBD: Y442L and N479K. These mutations are predicted to form polar interactions with N30 and N31 of mACE2, and the change of Y442L removes a bulky side chain permitting access and enhancing binding of K479 to N30 and N31 (Frieman et al., 2012) . The v2163 strain contains mutations, Y436H and Y442F. As described above the Y436H mutation most likely compensates for mACE2 353H. The extent of steric clash between N31 of mACE2 and Y442 has not been described; however, the Y442F change removes a hydroxyl group from the binding interface and this is predicted to enhance the interaction with mACE2 (Frieman et al., 2012) .The mouse adaptation studies yielded several SARS-CoV strains capable of causing lethal disease in mice. These strains represent an advance in the development of an animal model for the \"Animal Rule\" though the disease mechanism in young mice is different from that in humans. The use of the MA15 virus in aged mice has proved to be a valuable model for the study of SARS-CoV vaccine candidates. Studies examining mutations that arose upon serial passage and detailed analysis of S protein ACE2 interactions emphasize the role of the S protein in host restriction and demonstrate that the S protein-host receptor interactions are critical for the development of animal models. This is further emphasized by the finding that transgenic mice expressing hACE2 and mouse-adapted SARS-CoV strains both show enhanced replication and disease. As our understanding of host-receptor interactions develops, application of this knowledge will facilitate the development animal models for emerging coronaviruses.\n",
      "\n",
      "Role of host receptor DPP4 in animal models of MERS-CoV\n",
      "\n",
      "To understand the restriction of MERS-CoV replication in small animals, evidence of host restriction at the level of DPP4 sequence was sought. The crystal structure of the S protein bound to DPP4 has been solved Lu et al., 2013) . At the interface between the S protein RBD and DPP4, 14 residues of the S protein RBD have direct contact with 15 residues of hDPP4 (see Table 2 ) . The interaction between DPP4 and the S protein RBD has two major binding patches. Patch 1 consists of hDPP4 residues K267 and R336 interacting with a negatively charged surface consisting of E536, D537, and D539 of the S protein RBD. In addition, Y499 of the S protein RBD forms a hydrogen bond with R336 of DPP4 Lu et al., 2013) . The second major binding patch consists of DPP4 residues L294, I295, H298, R317, and Q344. Residues L294 and I295 interact with S protein RBD residues L506, W553, and V555, and DPP4 residues R317 and Q344 form a salt-bridge and hydrogen bond with S protein RBD residues D510 and E513, respectively.As mentioned above, initial studies with chimeric DPP4 proteins demonstrated that incorporation of the human DPP4 S protein RBD (residues 246-505) into ferret DPP4 rendered ferret cells susceptible to MERS-CoV infection . To further understand the role of the S protein RBD in host restriction, subsequent studies compared the MERS-CoV S protein binding affinity of human and mouse DPP4, and that of several potential zoonotic reservoir species including camels, horses, goats, and bats (Barlan et al., 2014) . Introduction of the human DPP4 S protein binding domain into mouse DPP4 rendered mouse cells susceptible to MERS-CoV infection, thus emphasizing the role of the DPP4 sequence in host restriction. Comparison of human DPP4 binding affinity to that other species demonstrated that human DPP4 had the highest affinity for the S protein RBD, and affinity decreased as follows: human 4horses 4camels 4goats4bats. Expression of DPP4 from all these species rendered cells susceptible to infection, while mouse DPP4 did not permit infection (Barlan et al., 2014) . Further characterization of amino acid residues at the interface of DPP4 with the S protein RBD identified 6 differences between mouse and human DPP4 (see Table 2 ) (Barlan et al., 2014; van Doremalen et al., 2014; Cockrell et al., 2014) (Cockrell et al., 2014) . Introduction of the human DPP4 residues at all 5 sites in mouse DPP4 resulted in highly efficient infection. Selective mutation of only residues 336 and 346 associated with the patch 1 binding region, or residues 288, 294, 295 in the patch 2 domain did not restore highly efficient infection, indicating that interactions with both patch regions were required for high affinity DPP4-S protein binding. In support of this finding, the introduction of human residues A294L and T330R associated with patch 1 and 2, respectively, resulted in efficient infection (Cockrell et al., 2014) .In the context of the hamster model, expression of human DPP4 in non-permissive (BHK) hamster cells, rendered cells susceptible to MERS-CoV infection, indicating that host restriction occurred at the level of the receptor . Comparison of the hamster and human DPP4 sequences identified five amino acid differences in the DPP4 S protein RBD interface (Table 2) . Introduction of the human residues into hamster DPP4 permitted infection of hamster cells, and modeling studies suggested that two residues at positions 291 and 336 were largely responsible for the host restriction . This is in agreement with studies on mouse DPP4 that show mutation R336T, also present in the hamster DPP4, decreases infection by MERS-CoV (Cockrell et al., 2014) .Collectively, these studies demonstrate that host restriction of MERS-CoV is predominantly dictated by DPP4 sequence. To explore additional animal models we sequenced cotton rat DPP4 (see Table 2 ) and found the S protein binding residues to be similar to those of the hamster and ferret, suggesting that cotton rats would be refractory to infection. Indeed comparison of human, rhesus macaque and common marmoset DPP4 sequences show 100% identity at the residues that interact with MERS-CoV S protein. However, the differences in disease severity between Rhesus macaques and common marmosets indicate that other host factors such as the presence or expression levels of S-cleaving proteases (i.e. TMPRSS2) (Cockrell et al., 2014) may influence infection and disease severity. Regardless of additional host factors, the interaction of DPP4 with MERS-CoV S protein should be the initial and predominant focus of small animal model development.\n",
      "\n",
      "Approaches to developing small animal models of MERS-CoV infection\n",
      "\n",
      "Development of animal models for SARS-CoV demonstrated that both mouse adaptation and the generation of transgenic mice expressing hACE2 resulted in enhanced permissiveness and disease. Moving forward with animal models of MERS-CoV, similar strategies should be utilized. Mouse adaptation, or adaptation to ferrets or hamsters, is unlikely to be fruitful approaches because infectious virus could not be isolated from these animals and the MERS-CoV S protein failed to bind DPP4 from these species. To overcome this barrier, reverse genetics approaches could be used to introduce mutations into the MERS-CoV S protein RBD to enhance or promote interaction with DPP4 of different species. Residues in patch 1 are underlined and residues in patch 2 are in italics and underlined. n Predicted sequence. This has particular utility in outbred animals in which genetic manipulation of the host receptor would be challenging. As demonstrated with SARS-CoV, the generation of mice expressing human DPP4 may be the most rapid strategy to yield a small animal model. Indeed, when mice were transduced with an adenovirus vector that expressed human DPP4, they were susceptible to MERS-CoV infection and developed pneumonia, albeit without associated mortality . Transgenic mice could be generated via traditional methods or using the CRISPR-Cas9 (Doudna and Charpentier, 2014) system to replace mouse DPP4 with human DPP4 or to introduce a mouse DPP4 carrying the mutations that promote S protein binding. With either transgenic strategy or with the development of a reverse genetics adapted strain, replication and pathogenesis will have to be characterized to meet the criteria for the FDA Animal Rule.Despite the lack of suitable models, several groups are developing vaccines and therapeutics against MERS-CoV (Zhang et al., 2014a (Zhang et al., , 2014b Chan et al., 2013; Hart et al., 2014; Coleman et al., 2014b; de Wilde et al., 2014; Dyall et al., 2014; Kim et al., 2014) . Vaccine candidates are being evaluated for immunogenicity and antivirals are being evaluated in vitro. Medical countermeasures have the potential to advance along the path towards regulatory approval if a susceptible small animal model can be developed and used in conjunction with the marmoset model. In concert with public health efforts, novel therapies could curb the on-going MERS-CoV epidemic and reduce the morbidity and mortality associated with MERS-CoV.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clean_pdf_df.text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform text:\n",
    "Text column of a dataframe --> dictionarity (keys: paragraph name, values: content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=4, stop=10, step=1)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_sample.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_text_to_dict(df,col_name,output_col,print_it=False):\n",
    "    text_list=[]\n",
    "    for i in df.index:\n",
    "        line = df.loc[i]\n",
    "        text=str(line[col_name])\n",
    "        text_dict=dict()\n",
    "        comp_list= text.split(\"\\n\\n\")\n",
    "        for num in range(int((len(comp_list))/2)):\n",
    "            key_str=str(num)+'_'+str(comp_list[num*2])\n",
    "            key_str=key_str.strip()\n",
    "            text_dict[key_str]=str(comp_list[num*2+1])\n",
    "        text_list.append(text_dict)\n",
    "        if print_it ==True:\n",
    "            print(i)\n",
    "    df[output_col]=text_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_dataframe=df_text_to_dict(clean_pdf_df,\"text\",\"text_dict\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>affiliations</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "      <th>bibliography</th>\n",
       "      <th>raw_authors</th>\n",
       "      <th>raw_bibliography</th>\n",
       "      <th>text_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ae02f293c03e3e1a2d4582e62c22f2c0c291f48</td>\n",
       "      <td>Development of animal models against emerging ...</td>\n",
       "      <td>Troy C Sutton, Kanta Subbarao</td>\n",
       "      <td>Troy C Sutton (NIAID, NIH, United States), Kan...</td>\n",
       "      <td>Abstract\\n\\nTwo novel coronaviruses have emerg...</td>\n",
       "      <td>Introduction\\n\\nWithin the last two decades, t...</td>\n",
       "      <td>Replication and shedding of MERS-CoV in upper ...</td>\n",
       "      <td>[{'first': 'Troy', 'middle': ['C'], 'last': 'S...</td>\n",
       "      <td>{'BIBREF0': {'ref_id': 'b0', 'title': 'Replica...</td>\n",
       "      <td>{'0_Introduction': 'Within the last two decade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>640de65e9f09545c463bc419bffb7084fc40fae5</td>\n",
       "      <td>X-RAY CRYSTALLOGRAPHIC STUDIES OF THE IDIOTYPI...</td>\n",
       "      <td>Nenad Ban, Alexander Mcpherson</td>\n",
       "      <td>Nenad Ban (University of California, 92521, Ri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n1. viral: type B viral hepatitis (Kennedy ...</td>\n",
       "      <td>Three-dimensional structure of antibodies, P M...</td>\n",
       "      <td>[{'first': 'Nenad', 'middle': [], 'last': 'Ban...</td>\n",
       "      <td>{'BIBREF0': {'ref_id': 'b0', 'title': 'Three-d...</td>\n",
       "      <td>{'0_': '1. viral: type B viral hepatitis (Kenn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id                                              title                         authors                                       affiliations                                           abstract                                               text                                       bibliography                                        raw_authors                                   raw_bibliography                                          text_dict\n",
       "0  0ae02f293c03e3e1a2d4582e62c22f2c0c291f48  Development of animal models against emerging ...   Troy C Sutton, Kanta Subbarao  Troy C Sutton (NIAID, NIH, United States), Kan...  Abstract\\n\\nTwo novel coronaviruses have emerg...  Introduction\\n\\nWithin the last two decades, t...  Replication and shedding of MERS-CoV in upper ...  [{'first': 'Troy', 'middle': ['C'], 'last': 'S...  {'BIBREF0': {'ref_id': 'b0', 'title': 'Replica...  {'0_Introduction': 'Within the last two decade...\n",
       "1  640de65e9f09545c463bc419bffb7084fc40fae5  X-RAY CRYSTALLOGRAPHIC STUDIES OF THE IDIOTYPI...  Nenad Ban, Alexander Mcpherson  Nenad Ban (University of California, 92521, Ri...                                                NaN  \\n\\n1. viral: type B viral hepatitis (Kennedy ...  Three-dimensional structure of antibodies, P M...  [{'first': 'Nenad', 'middle': [], 'last': 'Ban...  {'BIBREF0': {'ref_id': 'b0', 'title': 'Three-d...  {'0_': '1. viral: type B viral hepatitis (Kenn..."
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap_dataframe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_ap_dataframe=ap_dataframe[[\"paper_id\",\"text_dict\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0_', '1_FabD1.3(Abl>-FabE225(Ab2) and FabD1.3-Lysozyme Complex', '2_FvD1.3(Abl)-FvE5.2(Ab2) and FabD1.3-Lysozyme complex', '3_B', '4_THE ANTI-FELINE INFECTIOUS PERITONITIS VIRUS SYSTEM', '5_Description of the Structure', '6_Idiotope-Anti-Idiotope Interface', '7_ANTI-ANGIOTENSIN II SYSTEM', '8_Number of Residues in a Loop', '9_V8 (IH)', '10_ANTI-LIPOPOLYSACCHARIDE A ANTIGEN OF BRUCELLA ABORTUS SYSTEM', '11_SELF COMPLEMENTARITY OF A MONO-CLONAL ANTIBODY GENERATED IN AN IDIOTYPIC CASCADE', '12_Structure of the Fab Fragment', '13_The Packing of the Fab Fragment and Self-Complementary Interactions', '14_Ag', '15_The Structure of the Complex', '16_The Interface between Self Complementary Antianti-idiotopes', '17_Possible Implications of the Self-Complementary Interaction'])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_ap_dataframe.loc[1][\"text_dict\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_ap_dataframe[[\"paper_id\",\"text_dict\"]].to_csv(\"sm_appended_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ap_dataframe.to_csv(\"appended_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=sm_ap_dataframe[[\"paper_id\",\"text_dict\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_dict=dict()\n",
    "for i in range(sm.shape[0]):\n",
    "    sm_dict[sm.paper_id[i]]=sm.text_dict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>text_dict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ae02f293c03e3e1a2d4582e62c22f2c0c291f48</td>\n",
       "      <td>{'0_Introduction': 'Within the last two decade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>640de65e9f09545c463bc419bffb7084fc40fae5</td>\n",
       "      <td>{'0_': '1. viral: type B viral hepatitis (Kenn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5da136317f5b97ed8371d5121d8828f1c9a5372d</td>\n",
       "      <td>{'0_Introduction': 'Malaria is a mosquito-born...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f9ae3db6ac88670b3f47b815bb7422a75f6d47c8</td>\n",
       "      <td>{'0_Introduction': 'Nearly 3 million confirmed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a8676c57d7e3a52378b9e554cc0886ad91999e13</td>\n",
       "      <td>{'0_': 'ziektegeschiedenis Patiënt A, een 29-j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id                                          text_dict\n",
       "0  0ae02f293c03e3e1a2d4582e62c22f2c0c291f48  {'0_Introduction': 'Within the last two decade...\n",
       "1  640de65e9f09545c463bc419bffb7084fc40fae5  {'0_': '1. viral: type B viral hepatitis (Kenn...\n",
       "2  5da136317f5b97ed8371d5121d8828f1c9a5372d  {'0_Introduction': 'Malaria is a mosquito-born...\n",
       "3  f9ae3db6ac88670b3f47b815bb7422a75f6d47c8  {'0_Introduction': 'Nearly 3 million confirmed...\n",
       "4  a8676c57d7e3a52378b9e554cc0886ad91999e13  {'0_': 'ziektegeschiedenis Patiënt A, een 29-j..."
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sm_appended_df.json\",'a') as outfile:\n",
    "    json.dump(sm_dict,outfile,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm_dict.to_json(\"sm_appended_df.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sm_ap_dataframe[[\"paper_id\",\"text_dict\"]].to_json(\"sm_appended_df.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Q_A Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, answer_text):\n",
    "    '''\n",
    "    Takes a `question` string and an `answer_text` string (which contains the\n",
    "    answer), and identifies the words within the `answer_text` that are the\n",
    "    answer. Prints them out.\n",
    "    '''\n",
    "    # ======== Tokenize ========\n",
    "    # Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "    input_ids = tokenizer.encode(question, answer_text,max_length=500\n",
    "                                )\n",
    "\n",
    "    # Report how long the input sequence is.\n",
    "    #print('Query has {:,} tokens.\\n'.format(len(input_ids)))\n",
    "\n",
    "    # ======== Set Segment IDs ========\n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    # The number of segment A tokens includes the [SEP] token istelf.\n",
    "    num_seg_a = sep_index + 1\n",
    "\n",
    "    # The remainder are segment B.\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # Construct the list of 0s and 1s.\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    # There should be a segment_id for every input token.\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "    # ======== Evaluate ========\n",
    "    # Run our example question through the model.\n",
    "    start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                                    token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\n",
    "\n",
    "    # ======== Reconstruct Answer ========\n",
    "    # Find the tokens with the highest `start` and `end` scores.\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "    \n",
    "    \n",
    "    # Get the string versions of the input tokens.\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "    # Start with the first token.\n",
    "    answer = tokens[answer_start]\n",
    "\n",
    "    # Select the remaining answer tokens and join them with whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "        \n",
    "        # If it's a subword token, then recombine it with the previous token.\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "        \n",
    "        # Otherwise, add a space then the token.\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "            \n",
    "    s_scores = start_scores.detach().numpy().flatten()\n",
    "    e_scores = end_scores.detach().numpy().flatten()\n",
    "    #print('score:'+(start_scores)+\"; \"+str(end_scores))\n",
    "    #print('score:'+str(max(s_scores))+\"; \"+str(min(e_scores)))\n",
    "    #print(str(tensor[torch.argmax(start_scores)]))\n",
    "    #print('Answer: \"' + answer + '\"')\n",
    "    return [answer,str(max(s_scores)),len(input_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in clean_pdf_df.text:\\n    answer_question(\"What do we know about Hypertension?\",i)\\n'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in clean_pdf_df.text:\n",
    "    answer_question(\"What do we know about Hypertension?\",i)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_example=\"What do we know about Hypertension?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q_example_a=\"[CLS] what do we know about hypertension ? [SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blood pressure\n",
      "0.500568\n",
      "330\n",
      "excess variability\n",
      "0.032215476\n",
      "36\n",
      "analogs of known chemical compounds are sometimes more effective than the parent molecule\n",
      "0.5907004\n",
      "77\n",
      "no key lessons learned have been eliminated by merging these results .\n",
      "0.7678749\n",
      "100\n",
      "[SEP]\n",
      "0.06287956\n",
      "227\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-288-ea730d11853d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0manswer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manswer_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_example\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0ms_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manswer_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_example\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtoken_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manswer_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_example\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m\"[CLS]\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mQ_example_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-283-997f94ca03ff>\u001b[0m in \u001b[0;36manswer_question\u001b[0;34m(question, answer_text)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Run our example question through the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n\u001b[0;32m---> 34\u001b[0;31m                                     token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from answer_text\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# ======== Reconstruct Answer ========\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions)\u001b[0m\n\u001b[1;32m   1446\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m         )\n\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m         )\n\u001b[1;32m    738\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             )\n\u001b[1;32m    409\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     ):\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mself_attention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add self attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         )\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in ap_dataframe.index:\n",
    "    line=ap_dataframe.loc[i]\n",
    "    dct=line[\"text_dict\"]\n",
    "    for key in dct.keys():\n",
    "        answer=answer_question(Q_example,dct[key])[0]\n",
    "        s_score=answer_question(Q_example,dct[key])[1]\n",
    "        token_len=answer_question(Q_example,dct[key])[2]\n",
    "        if (answer!=\"[CLS]\") & (float(s_score)>0) & (answer!=Q_example_a):\n",
    "            print(answer)\n",
    "            print(s_score)\n",
    "            print(token_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNRVuaKSNFG8"
   },
   "source": [
    "Just to see exactly what the tokenizer is doing, let's print out the tokens with their IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Question Answering with a Fine-Tuned BERT.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0619db0363894129880d090367b4194a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c5547ffbd4143609051b231a14853e1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e044677b4fc4ffe809b318e8963e08a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1e6e46c1520d4a309d77a4ff7cc07900": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b6be0f1b89044c3a934f3eccf29cf54": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "461b9936e0864bc1aac73925b730ef7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b6be0f1b89044c3a934f3eccf29cf54",
      "placeholder": "​",
      "style": "IPY_MODEL_bd8a1fa1079448f585e87dafcd856bfc",
      "value": "100% 398/398 [00:00&lt;00:00, 11.2kB/s]"
     }
    },
    "49263ffffaee42438fc699c57fab7814": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "549ca681c27743aa8c28af40d2185900": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8665ab6d11084a6e980121c5475d8170",
       "IPY_MODEL_461b9936e0864bc1aac73925b730ef7f"
      ],
      "layout": "IPY_MODEL_0c5547ffbd4143609051b231a14853e1"
     }
    },
    "632ff7bd64cf4b2c92acee6f0f17d6db": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f6590ea2e9c14d3099b9999ce1a4602a",
       "IPY_MODEL_b3e5f72146e0406d9977465e9549419f"
      ],
      "layout": "IPY_MODEL_87719f2515a34ba49761e7f18772a90d"
     }
    },
    "6f9df97c25e84e7d8efccce6cde22fbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_94daf90c961945cdafc12178c3e357e4",
       "IPY_MODEL_82461e6ee22b44918d424f24245bdf0e"
      ],
      "layout": "IPY_MODEL_f3d792809e234442b6c888b56421479d"
     }
    },
    "82461e6ee22b44918d424f24245bdf0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8892ad9564d84ff190062d0a9d5d9f6f",
      "placeholder": "​",
      "style": "IPY_MODEL_e86b7da45ef6466ebf25f28c10df61b8",
      "value": "100% 1.34G/1.34G [00:33&lt;00:00, 40.4MB/s]"
     }
    },
    "8665ab6d11084a6e980121c5475d8170": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e6e46c1520d4a309d77a4ff7cc07900",
      "max": 398,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_49263ffffaee42438fc699c57fab7814",
      "value": 398
     }
    },
    "87719f2515a34ba49761e7f18772a90d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8892ad9564d84ff190062d0a9d5d9f6f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "930457a02cbe469181b0dbaf1eb9fac0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94daf90c961945cdafc12178c3e357e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_930457a02cbe469181b0dbaf1eb9fac0",
      "max": 1340675298,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0e044677b4fc4ffe809b318e8963e08a",
      "value": 1340675298
     }
    },
    "b3e5f72146e0406d9977465e9549419f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c17dfd9c89694880a04d07942db3e426",
      "placeholder": "​",
      "style": "IPY_MODEL_0619db0363894129880d090367b4194a",
      "value": "100% 232k/232k [00:00&lt;00:00, 1.18MB/s]"
     }
    },
    "bd8a1fa1079448f585e87dafcd856bfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf4308a7859f4bfd9356215bbd9ef5e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c17dfd9c89694880a04d07942db3e426": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0989443c5e84d6b8eeee08879c07db6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e86b7da45ef6466ebf25f28c10df61b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3d792809e234442b6c888b56421479d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6590ea2e9c14d3099b9999ce1a4602a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0989443c5e84d6b8eeee08879c07db6",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bf4308a7859f4bfd9356215bbd9ef5e4",
      "value": 231508
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
