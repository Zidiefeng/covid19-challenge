{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "\n",
    "In this notebook, I quickly explore the `biorxiv` subset of the papers. Since it is stored in JSON format, the structure is likely too complex to directly perform analysis. Thus, I not only explore the structure of those files, but I also provide the following helper functions for you to easily format inner dictionaries from each file:\n",
    "* `format_name(author)`\n",
    "* `format_affiliation(affiliation)`\n",
    "* `format_authors(authors, with_affiliation=False)`\n",
    "* `format_body(body_text)`\n",
    "* `format_bib(bibs)`\n",
    "\n",
    "Feel free to reuse those functions for your own purpose! If you do, please leave a link to this notebook.\n",
    "\n",
    "Throughout the EDA, I show you how to use each of those files. At the end, I show you how to generate a clean version of the `biorxiv` as well as all the other datasets, which you can directly use by choosing this notebook as a data source (\"File\" -> \"Add or upload data\" -> \"Kernel Output File\" tab -> search the name of this notebook).\n",
    "\n",
    "### Update Log\n",
    "\n",
    "* V9: First release.\n",
    "* V10: Updated paths to include the [14k new papers](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/discussion/137474)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unhide the cell below to find the definition of the following functions:\n",
    "* `format_name(author)`\n",
    "* `format_affiliation(affiliation)`\n",
    "* `format_authors(authors, with_affiliation=False)`\n",
    "* `format_body(body_text)`\n",
    "* `format_bib(bibs)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def format_name(author):\n",
    "    middle_name = \" \".join(author['middle'])\n",
    "    \n",
    "    if author['middle']:\n",
    "        return \" \".join([author['first'], middle_name, author['last']])\n",
    "    else:\n",
    "        return \" \".join([author['first'], author['last']])\n",
    "\n",
    "\n",
    "def format_affiliation(affiliation):\n",
    "    text = []\n",
    "    location = affiliation.get('location')\n",
    "    if location:\n",
    "        text.extend(list(affiliation['location'].values()))\n",
    "    \n",
    "    institution = affiliation.get('institution')\n",
    "    if institution:\n",
    "        text = [institution] + text\n",
    "    return \", \".join(text)\n",
    "\n",
    "def format_authors(authors, with_affiliation=False):\n",
    "    name_ls = []\n",
    "    \n",
    "    for author in authors:\n",
    "        name = format_name(author)\n",
    "        if with_affiliation:\n",
    "            affiliation = format_affiliation(author['affiliation'])\n",
    "            if affiliation:\n",
    "                name_ls.append(f\"{name} ({affiliation})\")\n",
    "            else:\n",
    "                name_ls.append(name)\n",
    "        else:\n",
    "            name_ls.append(name)\n",
    "    \n",
    "    return \", \".join(name_ls)\n",
    "\n",
    "def format_body(body_text):\n",
    "    texts = [(di['section'], di['text']) for di in body_text]\n",
    "    texts_di = {di['section']: \"\" for di in body_text}\n",
    "    \n",
    "    for section, text in texts:\n",
    "        texts_di[section] += text\n",
    "\n",
    "    body = \"\"\n",
    "\n",
    "    for section, text in texts_di.items():\n",
    "        body += section\n",
    "        body += \"\\n\\n\"\n",
    "        body += text\n",
    "        body += \"\\n\\n\"\n",
    "    \n",
    "    return body\n",
    "\n",
    "def format_bib(bibs):\n",
    "    if type(bibs) == dict:\n",
    "        bibs = list(bibs.values())\n",
    "    bibs = deepcopy(bibs)\n",
    "    formatted = []\n",
    "    \n",
    "    for bib in bibs:\n",
    "        bib['authors'] = format_authors(\n",
    "            bib['authors'], \n",
    "            with_affiliation=False\n",
    "        )\n",
    "        formatted_ls = [str(bib[k]) for k in ['title', 'authors', 'venue', 'year']]\n",
    "        formatted.append(\", \".join(formatted_ls))\n",
    "\n",
    "    return \"; \".join(formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unhide the cell below to find the definition of the following functions:\n",
    "* `load_files(dirname)`\n",
    "* `generate_clean_df(all_files)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def load_files(dirname):\n",
    "    filenames = os.listdir(dirname)\n",
    "    raw_files = []\n",
    "\n",
    "    for filename in tqdm(filenames):\n",
    "        filename = dirname + filename\n",
    "        file = json.load(open(filename, 'rb'))\n",
    "        raw_files.append(file)\n",
    "    \n",
    "    return raw_files\n",
    "\n",
    "def generate_clean_df(all_files):\n",
    "    cleaned_files = []\n",
    "    \n",
    "    for file in tqdm(all_files):\n",
    "        features = [\n",
    "            file['paper_id'],\n",
    "            file['metadata']['title'],\n",
    "            format_authors(file['metadata']['authors']),\n",
    "            format_authors(file['metadata']['authors'], \n",
    "                           with_affiliation=True),\n",
    "            format_body(file['abstract']),\n",
    "            format_body(file['body_text']),\n",
    "            format_bib(file['bib_entries']),\n",
    "            file['metadata']['authors'],\n",
    "            file['bib_entries']\n",
    "        ]\n",
    "\n",
    "        cleaned_files.append(features)\n",
    "\n",
    "    col_names = ['paper_id', 'title', 'authors',\n",
    "                 'affiliations', 'abstract', 'text', \n",
    "                 'bibliography','raw_authors','raw_bibliography']\n",
    "\n",
    "    clean_df = pd.DataFrame(cleaned_files, columns=col_names)\n",
    "    clean_df.head()\n",
    "    \n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biorxiv: Exploration\n",
    "\n",
    "Let's first take a quick glance at the `biorxiv` subset of the data. We will also use this opportunity to load all of the json files into a list of **nested** dictionaries (each `dict` is an article)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv/pdf_json/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e441e7d98c75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbiorxiv_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/input/CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv/pdf_json/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbiorxiv_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of articles retrieved from biorxiv:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv/pdf_json/'"
     ]
    }
   ],
   "source": [
    "biorxiv_dir = '/kaggle/input/CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv/pdf_json/'\n",
    "filenames = os.listdir(biorxiv_dir)\n",
    "print(\"Number of articles retrieved from biorxiv:\", len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "\n",
    "for filename in filenames:\n",
    "    filename = biorxiv_dir + filename\n",
    "    file = json.load(open(filename, 'rb'))\n",
    "    all_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = all_files[0]\n",
    "print(\"Dictionary keys:\", file.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biorxiv: Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The abstract dictionary is fairly simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(file['abstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biorxiv: body text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first probe what the `body_text` dictionary looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"body_text type:\", type(file['body_text']))\n",
    "print(\"body_text length:\", len(file['body_text']))\n",
    "print(\"body_text keys:\", file['body_text'][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look at the first part of the `body_text` content. As you will notice, the body text is separated into a list of small subsections, each containing a `section` and a `text` key. Since multiple subsection can have the same section, we need to first group each subsection before concatenating everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"body_text content:\")\n",
    "pprint(file['body_text'][:2], depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the grouped section titles are for the example above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [(di['section'], di['text']) for di in file['body_text']]\n",
    "texts_di = {di['section']: \"\" for di in file['body_text']}\n",
    "for section, text in texts:\n",
    "    texts_di[section] += text\n",
    "\n",
    "pprint(list(texts_di.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example shows what the final result looks like, after we format each section title with its content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = \"\"\n",
    "\n",
    "for section, text in texts_di.items():\n",
    "    body += section\n",
    "    body += \"\\n\\n\"\n",
    "    body += text\n",
    "    body += \"\\n\\n\"\n",
    "\n",
    "print(body[:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below lets you display the body text in one line (unhide to see exactly the same as above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "print(format_body(file['body_text'])[:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biorxiv: Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see what keys are contained in the `metadata` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_files[0]['metadata'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at each of the correspond values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_files[0]['metadata']['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = all_files[0]['metadata']['authors']\n",
    "pprint(authors[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `format_name` and `format_affiliation` functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in authors:\n",
    "    print(\"Name:\", format_name(author))\n",
    "    print(\"Affiliation:\", format_affiliation(author['affiliation']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take as an example a slightly longer list of authors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(all_files[4]['metadata'], depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I provide the function `format_authors` that let you format a list of authors to get a final string, with the optional argument of showing the affiliation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = all_files[4]['metadata']['authors']\n",
    "print(\"Formatting without affiliation:\")\n",
    "print(format_authors(authors, with_affiliation=False))\n",
    "print(\"\\nFormatting with affiliation:\")\n",
    "print(format_authors(authors, with_affiliation=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biorxiv: bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the bibliography section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibs = list(file['bib_entries'].values())\n",
    "pprint(bibs[:2], depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can reused the `format_authors` function here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_authors(bibs[1]['authors'], with_affiliation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function let you format the bibliography all at once. It only extracts the title, authors, venue, year, and separate each entry of the bibliography with a `;`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bib_formatted = format_bib(bibs[:5])\n",
    "print(bib_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biorxiv: Generate CSV\n",
    "\n",
    "In this section, I show you how to manually generate the CSV files. As you can see, it's now super simple because of the `format_` helper functions. In the next sections, I show you have to generate them in 3 lines using the `load_files` and `generate_clean_dr` helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_files = []\n",
    "\n",
    "for file in tqdm(all_files):\n",
    "    features = [\n",
    "        file['paper_id'],\n",
    "        file['metadata']['title'],\n",
    "        format_authors(file['metadata']['authors']),\n",
    "        format_authors(file['metadata']['authors'], \n",
    "                       with_affiliation=True),\n",
    "        format_body(file['abstract']),\n",
    "        format_body(file['body_text']),\n",
    "        format_bib(file['bib_entries']),\n",
    "        file['metadata']['authors'],\n",
    "        file['bib_entries']\n",
    "    ]\n",
    "    \n",
    "    cleaned_files.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\n",
    "    'paper_id', \n",
    "    'title', \n",
    "    'authors',\n",
    "    'affiliations', \n",
    "    'abstract', \n",
    "    'text', \n",
    "    'bibliography',\n",
    "    'raw_authors',\n",
    "    'raw_bibliography'\n",
    "]\n",
    "\n",
    "clean_df = pd.DataFrame(cleaned_files, columns=col_names)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('biorxiv_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CSV: Custom (PMC), Commercial, Non-commercial licenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmc_dir = '/kaggle/input/CORD-19-research-challenge/custom_license/custom_license/pdf_json/'\n",
    "pmc_files = load_files(pmc_dir)\n",
    "pmc_df = generate_clean_df(pmc_files)\n",
    "pmc_df.to_csv('clean_pmc.csv', index=False)\n",
    "pmc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_dir = '/kaggle/input/CORD-19-research-challenge/comm_use_subset/comm_use_subset/pdf_json/'\n",
    "comm_files = load_files(comm_dir)\n",
    "comm_df = generate_clean_df(comm_files)\n",
    "comm_df.to_csv('clean_comm_use.csv', index=False)\n",
    "comm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noncomm_dir = '/kaggle/input/CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/pdf_json/'\n",
    "noncomm_files = load_files(noncomm_dir)\n",
    "noncomm_df = generate_clean_df(noncomm_files)\n",
    "noncomm_df.to_csv('clean_noncomm_use.csv', index=False)\n",
    "noncomm_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
